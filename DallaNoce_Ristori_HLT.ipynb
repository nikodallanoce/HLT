{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "DallaNoce_Ristori_HLT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ZYveYZaAJ4CK",
        "sGX5wZEjNSnO",
        "nQ9zRkqAPpDr",
        "hzjwWWkWQQW0",
        "7E-8waaOQ9_x",
        "5lSeCXnFRLUo",
        "ZeUIc8CARPLg",
        "btGbS2DvTRzS",
        "jh6qz5N7Tf3v",
        "sJ52WxcYf75B"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5gTl7VXJiwo"
      },
      "source": [
        "**Human Language Technologies Project**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmyUEYbqJqPs"
      },
      "source": [
        "**Authors:** Dalla Noce Niko, Ristori Alessandro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwktbIvfJJ71"
      },
      "source": [
        "#HLT Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsAoE5E4SUuh"
      },
      "source": [
        "This work is higly based on the tensorflow tutorial https://www.tensorflow.org/text/tutorials/transformer, our aim was to introduce BERT as an encoder in the model and try combinations with different architectures (both RNNs and transformers)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYveYZaAJ4CK"
      },
      "source": [
        "##Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0xEHybmMaM3"
      },
      "source": [
        "We need to install the transformers package to use the models and tokenizers from HuggingFace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cE9UOT6MJG_7",
        "outputId": "068ec6b5-3cbd-4b05-b5a7-52a93d3585f5"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.11.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.19)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LG8LIQXIKSc4"
      },
      "source": [
        "Import the libraries needed for the project to work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTS92bWiKIQx"
      },
      "source": [
        "import logging\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOBsbNdFMrNh"
      },
      "source": [
        "The model training is going to run on TPUs since they are the optimized for working with tensors, to do so we need colab to assign us as much TPUs as possible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWGEpMKhKiko",
        "outputId": "e1260a9d-f624-4f69-daf2-da0a078fb100"
      },
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.3.163.74:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.3.163.74:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSN8UPU5LJ2m"
      },
      "source": [
        "logging.getLogger('tensorflow').setLevel(logging.ERROR)  # suppress warnings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orp8P-ImLWro"
      },
      "source": [
        "##Preprocess the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC2VjPj2LzhY"
      },
      "source": [
        "Let's define the method to preprocess the anki dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfG1lSnbLZyl"
      },
      "source": [
        "def create_dataset_anki(name: str, preprocessed:bool) -> (list, list):\n",
        "    with open(name, encoding=\"UTF-8\") as datafile:\n",
        "        src_set = list()\n",
        "        dst_set = list()\n",
        "        for sentence in datafile:\n",
        "            sentence = sentence.split(\"\\t\")\n",
        "            src_set.append(sentence[0])\n",
        "            if preprocessed:\n",
        "                dst_set.append(sentence[1].split(\"\\n\")[0])\n",
        "            else:\n",
        "                dst_set.append(sentence[1])\n",
        "\n",
        "    return src_set, dst_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgPVmTY7L6Tf"
      },
      "source": [
        "We assume that the dataset was uploaded on colab with a zip file, we need to extract it and then we can build our lists using the previous method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gamUp8XiLrwB",
        "outputId": "b66a2dfa-2294-46d0-e9ea-7dbab66e0c7c"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"dataset_anki_it.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"\")\n",
        "\n",
        "en_set, it_set = create_dataset_anki(\"ita_preprocessed.txt\", True)\n",
        "print(\"Il corpus ha dimensione: {0}\".format(len(en_set)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Il corpus ha dimensione: 352040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGX5wZEjNSnO"
      },
      "source": [
        "##Build the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUn2kITYNVa3"
      },
      "source": [
        "Before we create the dataset from our lists, we have to tokenize each sentence from the corpus by using the BERT tokenizer for english and the one for italian. Moreover we can get the number of tokens for both source and target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7r7wQatNVDs"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Create the tokenizers and get the number of tokens\n",
        "tokenizer_en = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "tokenizer_it = BertTokenizer.from_pretrained(\"dbmdz/bert-base-italian-uncased\")\n",
        "v_size_en = tokenizer_en.vocab_size\n",
        "v_size_it = tokenizer_it.vocab_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdfUZv0YOL1I"
      },
      "source": [
        "# Tokenize the dataset\n",
        "tokens_en = tokenizer_en(en_set[:15000], add_special_tokens=True,\n",
        "                          truncation=True, padding=\"max_length\", return_attention_mask=True,\n",
        "                          return_tensors=\"tf\", max_length=30).data[\"input_ids\"]\n",
        "tokens_it = tokenizer_it(it_set[:15000], add_special_tokens=True,\n",
        "                          truncation=True, padding=\"max_length\", return_attention_mask=True,\n",
        "                          return_tensors=\"tf\", max_length=30).data[\"input_ids\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2dwetveOqdO"
      },
      "source": [
        "Then we build the tf dataset and we split it in training, validation and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZDQBwuPOxEU"
      },
      "source": [
        "def split_set(dataset: tf.data.Dataset,\n",
        "              tr: float = 0.8,\n",
        "              val: float = 0.1,\n",
        "              ts: float = 0.1,\n",
        "              shuffle: bool = True) -> (tf.data.Dataset, tf.data.Dataset, tf.data.Dataset):\n",
        "    if tr+val+ts != 1:\n",
        "        raise ValueError(\"Train, validation and test partition not allowed with such splits\")\n",
        "\n",
        "    dataset_size = dataset.cardinality().numpy()\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(dataset_size)\n",
        "\n",
        "    tr_size = int(tr * dataset_size)\n",
        "    val_size = int(val * dataset_size)\n",
        "\n",
        "    tr_set = dataset.take(tr_size)\n",
        "    val_set = dataset.skip(tr_size).take(val_size)\n",
        "    ts_set = dataset.skip(tr_size).skip(val_size)\n",
        "    return tr_set, val_set, ts_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uc8054ACO3Zh",
        "outputId": "136c4673-6c18-4092-d321-cf379bfa2833"
      },
      "source": [
        "# Build the dataset and split it in train, validation and test\n",
        "dataset = tf.data.Dataset.from_tensor_slices((tokens_en, tokens_it))  # build the tf dataset\n",
        "tr_set, val_set, ts_set = split_set(dataset, 0.8, 0.1, 0.1)  # split the tf dataset\n",
        "print(\"Dimensione training set: {0}\".format(len(tr_set)))\n",
        "print(\"Dimensione validation set: {0}\".format(len(val_set)))\n",
        "print(\"Dimensione test set: {0}\".format(len(ts_set)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensione training set: 12000\n",
            "Dimensione validation set: 1500\n",
            "Dimensione test set: 1500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWU92FjKO9J3"
      },
      "source": [
        "After we have built our development and test set, we need to split the first one (both training and validation) in batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOiUgmSVPK1H"
      },
      "source": [
        "def make_batches(dataset_src_dst: tf.data.Dataset, batch_size: int):\n",
        "    return dataset_src_dst.cache().batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hkK5H8iPNqj"
      },
      "source": [
        "with strategy.scope():\n",
        "  tr_batches = make_batches(tr_set, 128)\n",
        "  val_batches = make_batches(val_set, 128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j05ef3mN-LnR",
        "outputId": "9ba30c97-e58b-4675-df70-abcbd9b95742"
      },
      "source": [
        "for en, it in tr_batches.take(1):\n",
        "  print(en.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQ9zRkqAPpDr"
      },
      "source": [
        "##Positional encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nfx4FqnxP8-H"
      },
      "source": [
        "Attention layers see their input as a set of vectors, with no sequential order. This model also doesn't contain any recurrent or convolutional layers. Because of this a \"positional encoding\" is added to give the model some information about the relative position of the tokens in the sentence.\n",
        "\n",
        "The positional encoding vector is added to the embedding vector. Embeddings represent a token in a d-dimensional space where tokens with similar meaning will be closer to each other. But the embeddings do not encode the relative position of tokens in a sentence. So after adding the positional encoding, tokens will be closer to each other based on the similarity of their meaning and their position in the sentence, in the d-dimensional space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ-kiJzePpzt"
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "\n",
        "  # apply sin to even indices in the array; 2i\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzjwWWkWQQW0"
      },
      "source": [
        "##Masking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LsUdToKQXGa"
      },
      "source": [
        "Mask all the pad tokens in the batch of sequence. It ensures that the model does not treat padding as the input. The mask indicates where pad value 0 is present: it outputs a 1 at those locations, and a 0 otherwise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLNVe-9SQSo3"
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32) #cambiato tf.math.equal in tf.math.not_equal\n",
        "\n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVaNZkusQaN8"
      },
      "source": [
        "The look-ahead mask is used to mask the future tokens in a sequence. In other words, the mask indicates which entries should not be used.\n",
        "\n",
        "This means that to predict the third token, only the first and second token will be used. Similarly to predict the fourth token, only the first, second and the third tokens will be used and so on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvFbrSHLQdcr"
      },
      "source": [
        "def create_look_ahead_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask  # (seq_len, seq_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX3K1uHFRyW9"
      },
      "source": [
        "##Encoder and decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQWBUtfjkPMl"
      },
      "source": [
        "As we know from the HLT course, NMT models are based on the encoder-decoder paradigm, therefore we have to build both. We based the architecture of those layers from the paper \"Attention is all you need\" from Vaswani et al."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZdCgcJpR11c"
      },
      "source": [
        "###Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43KG2XY8kiOT"
      },
      "source": [
        "The single layer of the encoder transformer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWOzO7bDR8dU"
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 layers_size: int,\n",
        "                 num_heads: int,\n",
        "                 dff: int,\n",
        "                 dropout: float = 0.1) -> None:\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = tf.keras.layers.MultiHeadAttention(num_heads, layers_size)\n",
        "\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "              tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "              tf.keras.layers.Dense(layers_size)  # (batch_size, seq_len, d_model)\n",
        "            ])\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(dropout)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(dropout)\n",
        "\n",
        "    def call(self, src_tokens: tf.Tensor, training: bool, mask: tf.Tensor) -> tf.Tensor:\n",
        "        attn_output = self.mha(src_tokens, src_tokens,\n",
        "                                       src_tokens, mask)  # (batch_size, input_seq_len, layers_size)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(src_tokens + attn_output)  # (batch_size, input_seq_len, layers_size)\n",
        "\n",
        "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, layers_size)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, layers_size)\n",
        "        return out2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVU-JlJ6SB9x"
      },
      "source": [
        "class EncoderTransformer(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, num_layers: int,\n",
        "                 layers_size: int,\n",
        "                 num_heads: int,\n",
        "                 dff: int,\n",
        "                 src_vocab_size: int,\n",
        "                 maximum_position_encoding: int,\n",
        "                 dropout: float = 0.1) -> None:\n",
        "        super(EncoderTransformer, self).__init__()\n",
        "\n",
        "        self.layers_size = layers_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(src_vocab_size, layers_size)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.layers_size)\n",
        "\n",
        "        self.enc_layers = [EncoderLayer(layers_size, num_heads, dff, dropout) for _ in range(num_layers)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "\n",
        "    def call(self, src_tokens: tf.Tensor, training: bool, mask: tf.Tensor) -> tf.Tensor:\n",
        "        seq_len = tf.shape(src_tokens)[1]\n",
        "\n",
        "        # adding embedding and position encoding.\n",
        "        x = self.embedding(src_tokens)  # (batch_size, input_seq_len, layers_size)\n",
        "        x *= tf.math.sqrt(tf.cast(self.layers_size, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i].call(x, training, mask)\n",
        "\n",
        "        return x  # (batch_size, input_seq_len, layers_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk5x1zELSFyl"
      },
      "source": [
        "###Decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WwlG430kpb7"
      },
      "source": [
        "The single layer of the decoder transformer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVmDmBHsSLHo"
      },
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self,\n",
        "                 layers_size: int,\n",
        "                 num_heads: int,\n",
        "                 dff: int,\n",
        "                 dropout=0.1) -> None:\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.mha1 = tf.keras.layers.MultiHeadAttention(num_heads, layers_size)\n",
        "        self.mha2 = tf.keras.layers.MultiHeadAttention(num_heads, layers_size)\n",
        "\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "              tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "              tf.keras.layers.Dense(layers_size)  # (batch_size, seq_len, d_model)\n",
        "            ])\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(dropout)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(dropout)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(dropout)\n",
        "\n",
        "    @tf.function()\n",
        "    def call(self,\n",
        "             dst_tokens: tf.Tensor,\n",
        "             enc_output: tf.Tensor,\n",
        "             training: bool,\n",
        "             look_ahead_mask: tf.Tensor,\n",
        "             padding_mask: tf.Tensor):\n",
        "        # enc_output.shape == (batch_size, input_seq_len, layers_size)\n",
        "        attn1, attn_weights_block1 = self.mha1(dst_tokens, dst_tokens, dst_tokens,\n",
        "                             look_ahead_mask, return_attention_scores=True)  # (batch_size, target_seq_len, layers_size)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(attn1 + dst_tokens)\n",
        "\n",
        "        attn2, attn_weights_block2 = self.mha2(out1,\n",
        "                                               enc_output, enc_output, padding_mask, return_attention_scores=True)  # (batch_size, target_seq_len, layers_size)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, layers_size)\n",
        "\n",
        "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, layers_size)\n",
        "\n",
        "        return out3, attn_weights_block1, attn_weights_block2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFQJbb3nSwhV"
      },
      "source": [
        "class DecoderTransformer(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_layers: int,\n",
        "                 layers_size: int,\n",
        "                 num_heads: int,\n",
        "                 dff: int,\n",
        "                 target_vocab_size: int,\n",
        "                 maximum_position_encoding: int, dropout=0.1) -> None:\n",
        "        super(DecoderTransformer, self).__init__()\n",
        "\n",
        "        self.layers_size = layers_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, layers_size)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, layers_size)\n",
        "\n",
        "        self.dec_layers = [DecoderLayer(layers_size, num_heads, dff, dropout) for _ in range(num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "\n",
        "    def call(self,\n",
        "             dst_tokens: tf.Tensor,\n",
        "             enc_output: tf.Tensor,\n",
        "             training: bool,\n",
        "             look_ahead_mask: tf.Tensor,\n",
        "             padding_mask: tf.Tensor) -> (tf.Tensor, tf.Tensor):\n",
        "        seq_len = tf.shape(dst_tokens)[1]\n",
        "        attention_weights = {}\n",
        "\n",
        "        x = self.embedding(dst_tokens)  # (batch_size, target_seq_len, layers_size)\n",
        "        x *= tf.math.sqrt(tf.cast(self.layers_size, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
        "            # x = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
        "\n",
        "            attention_weights[f'decoder_layer{i + 1}_block1'] = block1\n",
        "            attention_weights[f'decoder_layer{i + 1}_block2'] = block2\n",
        "\n",
        "        return x, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrss8nse_h4j",
        "outputId": "a9b54fd2-18ae-4985-d0b4-685e89532e67"
      },
      "source": [
        "sample_encoder = EncoderTransformer(num_layers=8, layers_size=512, num_heads=8,\n",
        "                         dff=2048, src_vocab_size=8500,\n",
        "                         maximum_position_encoding=10000)\n",
        "temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
        "\n",
        "print(sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "sample_decoder = DecoderTransformer(num_layers=8, layers_size=512, num_heads=8,\n",
        "                         dff=2048, target_vocab_size=8000,\n",
        "                         maximum_position_encoding=5000)\n",
        "temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "output, attn = sample_decoder(temp_input,\n",
        "                              enc_output=sample_encoder_output,\n",
        "                              training=False,\n",
        "                              look_ahead_mask=None,\n",
        "                              padding_mask=None)\n",
        "\n",
        "output.shape, attn['decoder_layer2_block2'].shape, sample_encoder_output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 62, 512)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 26, 512]),\n",
              " TensorShape([64, 8, 26, 62]),\n",
              " TensorShape([64, 62, 512]))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nOatGOPS12t"
      },
      "source": [
        "##Build the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zz517yyZS7cO"
      },
      "source": [
        "The model consists of the encoder, decoder and a final linear layer. The output of the decoder is the input to the linear layer and its output is returned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMc72ufbS_bh"
      },
      "source": [
        "class TransformerNMT(tf.keras.Model):\n",
        "\n",
        "    def __init__(self,\n",
        "                 encoder: tf.keras.layers.Layer,\n",
        "                 decoder: tf.keras.layers.Layer,\n",
        "                 dst_v_size: int,\n",
        "                 lan_src: str = \"english\",\n",
        "                 lan_dst: str = \"italian\") -> None:\n",
        "        super(TransformerNMT, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.lan_src = lan_src\n",
        "        self.lan_dst = lan_dst\n",
        "        self.final_layer = tf.keras.layers.Dense(dst_v_size)\n",
        "\n",
        "    def __create_masks(self, src: tf.Tensor, dst: tf.Tensor) -> (tf.Tensor, tf.Tensor):\n",
        "        # Encoder padding mask\n",
        "        enc_padding_mask = create_padding_mask(src)\n",
        "\n",
        "        # Used in the 2nd attention block in the decoder.\n",
        "        # This padding mask is used to mask the encoder outputs.\n",
        "        dec_padding_mask = create_padding_mask(src)\n",
        "\n",
        "        # Used in the 1st attention block in the decoder.\n",
        "        # It is used to pad and mask future tokens in the input received by\n",
        "        # the decoder.\n",
        "        look_ahead_mask = create_look_ahead_mask(tf.shape(dst)[1])\n",
        "        dec_target_padding_mask = create_padding_mask(dst)\n",
        "        look_ahead_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "        return enc_padding_mask, look_ahead_mask, dec_padding_mask\n",
        "\n",
        "    def call(self, inputs: list, training: bool) -> (tf.Tensor, tf.Tensor):\n",
        "        # Keras models prefer if you pass all your inputs in the first argument\n",
        "        src, dst = inputs\n",
        "\n",
        "        enc_padding_mask, look_ahead_mask, dec_padding_mask = self.__create_masks(src, dst)\n",
        "\n",
        "        enc_output = self.encoder(src, training, enc_padding_mask)  # (batch_size, inp_seq_len, layers_size)\n",
        "\n",
        "        # dec_output, attention_weights = self.decoder(dst, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "        dec_output, attention_weights = self.decoder(dst, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "        return final_output, attention_weights"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btGbS2DvTRzS"
      },
      "source": [
        "##Optmizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "busHjsItTWA5"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def get_config(self):\n",
        "        pass\n",
        "\n",
        "    def __init__(self, layers_size, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.layers_size = layers_size\n",
        "        self.layers_size = tf.cast(self.layers_size, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "        return tf.math.rsqrt(self.layers_size) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jh6qz5N7Tf3v"
      },
      "source": [
        "##Loss and metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ua0qSrATw-N"
      },
      "source": [
        "def loss_function(real, pred):\n",
        "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss_) / tf.reduce_sum(mask)\n",
        "\n",
        "\n",
        "def accuracy_function(real, pred):\n",
        "    accuracies = tf.equal(real, tf.argmax(pred, axis=2, output_type=tf.int32))\n",
        "\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    accuracies = tf.math.logical_and(mask, accuracies)\n",
        "\n",
        "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
        "    mask = tf.cast(mask, dtype=tf.float32)\n",
        "    return tf.reduce_sum(accuracies) / tf.reduce_sum(mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pl1cLbXBT3s0"
      },
      "source": [
        "with strategy.scope():\n",
        "  train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "  train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGO3ZxwhUIL1"
      },
      "source": [
        "##Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZhNk1fSUKJ9"
      },
      "source": [
        "with strategy.scope():\n",
        "    train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "    train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "\n",
        "    def __init__(self, transformer: TransformerNMT):\n",
        "        learning_rate = CustomSchedule(transformer.decoder.layers_size)\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "        self.transformer = transformer\n",
        "\n",
        "    @tf.function()\n",
        "    def __train_step(self, src: tf.Tensor, dst: tf.Tensor) -> None:\n",
        "        dst_inp = dst[:, :-1]\n",
        "        dst_real = dst[:, 1:]\n",
        "\n",
        "        @tf.function()\n",
        "        def step_fn(dst_inp, dst_real):\n",
        "            with tf.GradientTape() as tape:\n",
        "                predictions, _ = self.transformer([src, dst_inp], training=True)\n",
        "                loss = loss_function(dst_real, predictions)\n",
        "\n",
        "            gradients = tape.gradient(loss, self.transformer.trainable_variables)\n",
        "            self.optimizer.apply_gradients(zip(gradients, self.transformer.trainable_variables))\n",
        "\n",
        "            train_loss(loss)\n",
        "            train_accuracy(accuracy_function(dst_real, predictions))\n",
        "\n",
        "        strategy.run(step_fn, args=(dst_inp, dst_real))\n",
        "\n",
        "    def train(self, epochs: int, tr_batches) -> None:\n",
        "        for epoch in range(epochs):\n",
        "            start = time.time()\n",
        "\n",
        "            train_loss.reset_states()\n",
        "            train_accuracy.reset_states()\n",
        "\n",
        "            for (batch, (src, dst)) in enumerate(tr_batches):\n",
        "                self.__train_step(src, dst)\n",
        "\n",
        "                if batch % 50 == 0:\n",
        "                    print(\n",
        "                        f'Epoch {epoch + 1} Batch {batch} '\n",
        "                        f'Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "\n",
        "            if (epoch + 1) % 5 == 0:\n",
        "                pass\n",
        "                # print(\"save\")\n",
        "\n",
        "            print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "\n",
        "            print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccFwVc9HU70h"
      },
      "source": [
        "##Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ3VnYtqU9KQ",
        "outputId": "992945fc-64db-4790-db5c-d07bafbfdbf9"
      },
      "source": [
        "# Setup the hyperparameters\n",
        "num_layers = 6\n",
        "layers_size = 512\n",
        "dff = 2048\n",
        "num_heads = 8\n",
        "\n",
        "# Build the model\n",
        "encoder = EncoderTransformer(num_layers, layers_size, num_heads, dff, v_size_en, 30)\n",
        "decoder = DecoderTransformer(num_layers, layers_size, num_heads, dff, v_size_it, 30)\n",
        "model = TransformerNMT(encoder, decoder, v_size_it)\n",
        "\n",
        "# Build the trainer and train the model\n",
        "trainer = Trainer(model)\n",
        "trainer.train(3, tr_batches)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 10.3691 Accuracy 0.0000\n",
            "Epoch 1 Batch 50 Loss 9.7687 Accuracy 0.1460\n",
            "Epoch 1 Loss 9.3667 Accuracy 0.2218\n",
            "Time taken for 1 epoch: 222.84 secs\n",
            "\n",
            "Epoch 2 Batch 0 Loss 8.5318 Accuracy 0.3605\n",
            "Epoch 2 Batch 50 Loss 8.1160 Accuracy 0.3697\n",
            "Epoch 2 Loss 7.6993 Accuracy 0.3895\n",
            "Time taken for 1 epoch: 39.28 secs\n",
            "\n",
            "Epoch 3 Batch 0 Loss 6.7043 Accuracy 0.4573\n",
            "Epoch 3 Batch 50 Loss 6.0910 Accuracy 0.4972\n",
            "Epoch 3 Loss 5.5951 Accuracy 0.5302\n",
            "Time taken for 1 epoch: 39.29 secs\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjIo3f2ubjFd"
      },
      "source": [
        "model.save_weights(\"nmt_transformer_transformer.h5\")\n",
        "\n",
        "transformer_model = TransformerNMT(encoder, decoder, v_size_it)\n",
        "\n",
        "temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n",
        "temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "fn_out, _ = transformer_model([temp_input, temp_target], training=False)\n",
        "\n",
        "transformer_model.load_weights(\"nmt_transfomer_transformer.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJ52WxcYf75B"
      },
      "source": [
        "##Translator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miFhmV9Kf9oV"
      },
      "source": [
        "class Translator(tf.Module):\n",
        "    def __init__(self, src_tokenizer: BertTokenizer, targ_tokenizer: BertTokenizer, transformer: TransformerNMT) -> None:\n",
        "        super(Translator, self).__init__()\n",
        "        self.src_tokenizer = src_tokenizer\n",
        "        self.targ_tokenizer = targ_tokenizer\n",
        "        self.transformer = transformer\n",
        "\n",
        "    def __call__(self, sentence, max_length=30) -> str:\n",
        "        sentence_tok = self.src_tokenizer(sentence, padding='max_length', return_tensors='tf', max_length=max_length,\n",
        "                                          add_special_tokens=True).data['input_ids']\n",
        "\n",
        "        encoder_input = tf.reshape(sentence_tok, [1, max_length])\n",
        "\n",
        "        start_end = self.targ_tokenizer(\"\", padding='max_length', return_tensors='np',\n",
        "                                        max_length=3, add_special_tokens=True).data['input_ids']\n",
        "\n",
        "        start = tf.convert_to_tensor([start_end[0, 0]], dtype=tf.int32)\n",
        "        end = tf.convert_to_tensor([start_end[0, 1]], dtype=tf.int32)\n",
        "\n",
        "        # `tf.TensorArray` is required here (instead of a python list) so that the\n",
        "        # dynamic-loop can be traced by `tf.function`.\n",
        "        output_array = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)\n",
        "        output_array = output_array.write(0, start)\n",
        "\n",
        "        for i in tf.range(max_length):\n",
        "            output = tf.transpose(output_array.stack())\n",
        "            predictions, _ = self.transformer([encoder_input, output], training=False)\n",
        "\n",
        "            # select the last token from the seq_len dimension\n",
        "            predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "            predicted_id = tf.argmax(predictions, axis=-1, output_type=tf.int32)\n",
        "\n",
        "            # concatentate the predicted_id to the output which is given to the decoder\n",
        "            # as its input.\n",
        "            output_array = output_array.write(i + 1, predicted_id[0])\n",
        "\n",
        "            if predicted_id == end:\n",
        "                break\n",
        "\n",
        "        output = tf.transpose(output_array.stack())\n",
        "        output = output.numpy().tolist()[0]\n",
        "        # out = list()\n",
        "        # for r in output:\n",
        "        #    for e in r:\n",
        "        #        out.append(e)\n",
        "        \n",
        "        # text = self.targ_tokenizer.convert_ids_to_tokens(out)\n",
        "        text = self.targ_tokenizer.convert_ids_to_tokens(output)\n",
        "\n",
        "        return self.targ_tokenizer.convert_tokens_to_string(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMNTo2qZg-he"
      },
      "source": [
        "Let's try the translator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5QA2oyohAeM"
      },
      "source": [
        "# Build the translator\n",
        "translator = Translator(tokenizer_en, tokenizer_it, model)\n",
        "\n",
        "# Translate some examples\n",
        "out = translator(\"I want to beat you hard.\")\n",
        "print(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1eBFn5nksru"
      },
      "source": [
        "Da qui in poi va messo BERT."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECVK79hqpBAz"
      },
      "source": [
        "##BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm_8cYYUpD-x"
      },
      "source": [
        "class EncoderBERT(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, bert: TFBertModel) -> None:\n",
        "        self.bert = bert\n",
        "\n",
        "    def call(self, src_tokens: tf.Tensor, training: bool, mask: tf.Tensor) -> tf.Tensor:\n",
        "        print(bert)\n",
        "        mask = tf.ones(src_tokens.shape) - mask\n",
        "        output = self.bert([src_tokens, mask], training=training)[0]  # last_hidden_state\n",
        "        return output  # (batch_size, input_seq_len, layers_size)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SxwMtqLz3A8",
        "outputId": "fec36da6-5a7c-4a7e-b5cf-1135ec12362f"
      },
      "source": [
        "encoder_bert = EncoderBERT(TFBertModel.from_pretrained(\"bert-base-uncased\", trainable=False))\n",
        "decoder = DecoderTransformer(6, 512, 8, 2048, v_size_it, 10000)\n",
        "model_bert = TransformerNMT(encoder_bert, decoder, v_size_it)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "eHk8eCCC0Ub3",
        "outputId": "c242a844-e437-4539-f879-74acab6b556f"
      },
      "source": [
        "trainer = Trainer(model_bert)\n",
        "trainer.train(5, tr_batches)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0a85ff491d10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_bert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Trainer' is not defined"
          ]
        }
      ]
    }
  ]
}