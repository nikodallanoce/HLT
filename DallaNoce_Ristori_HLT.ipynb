{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "DallaNoce_Ristori_HLT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ztt9YLmZsWWM",
        "PxDWi1wVWzyn",
        "uyCr1wXRZM29",
        "mxl9EoWsZaUp",
        "r2dwetveOqdO",
        "0wrYPjy1dxwB",
        "3iZAS6kYsWWR",
        "eNH_DBR_Fwn0",
        "jZdCgcJpR11c",
        "Xk5x1zELSFyl"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d91e88ca621440019973b14d249c8a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_60cd70bc8f1545f382c4c7b4ddc1a2a1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a98414bdf3034c5396a91a4f10de5f73",
              "IPY_MODEL_1f7accae7f2b4260a6820fa1b8924dbd",
              "IPY_MODEL_8b64aee5b5c643638d74e37202d4690d"
            ]
          }
        },
        "60cd70bc8f1545f382c4c7b4ddc1a2a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a98414bdf3034c5396a91a4f10de5f73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bdfba53940b14ea8bd9dee7cfc2a5894",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "  6%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_233e1e8ba8514605a3d657266a63deb6"
          }
        },
        "1f7accae7f2b4260a6820fa1b8924dbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_801e9325caf641568ebb41c199e59522",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1012,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 63,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dd61a101c3ab49bbb66b7938fe92e2e9"
          }
        },
        "8b64aee5b5c643638d74e37202d4690d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b53858517b7648acae24f4f1fbc60e1d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 63/1012 [25:48&lt;6:21:41, 24.13s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d1976a46a44f4cc7b55e6a0c6fccadb3"
          }
        },
        "bdfba53940b14ea8bd9dee7cfc2a5894": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "233e1e8ba8514605a3d657266a63deb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "801e9325caf641568ebb41c199e59522": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dd61a101c3ab49bbb66b7938fe92e2e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b53858517b7648acae24f4f1fbc60e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d1976a46a44f4cc7b55e6a0c6fccadb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5gTl7VXJiwo"
      },
      "source": [
        "**Human Language Technologies Project**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmyUEYbqJqPs"
      },
      "source": [
        "**Authors:** Dalla Noce Niko, Ristori Alessandro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AKYoZs9jmP8"
      },
      "source": [
        "# **HLT Project**\n",
        "\n",
        "This work is higly based on the tensorflow tutorials https://www.tensorflow.org/text/tutorials/transformer and https://keras.io/examples/nlp/neural_machine_translation_with_transformer/, our aim was to implement some NMT models using the transformers from Hugginface.com as encoders in the models and evaluate their performances on the SacreBLEU score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztt9YLmZsWWM"
      },
      "source": [
        "## **Setup**\n",
        "We need to install the transformers package to use the models and tokenizers from HuggingFace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eHtucw_fBpQ",
        "outputId": "57a0e461-eef8-4409-84a4-2c56e3cbcd83"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkjsPkIosWWM"
      },
      "source": [
        "import logging\n",
        "import sentencepiece\n",
        "import random\n",
        "import numpy as np\n",
        "import tarfile\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngtpmviRXGsX"
      },
      "source": [
        "The model training is going to run on TPUs since they are the optimized for working with tensors, if there are no TPUs avilable then we work with a GPU instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hd5zB1G7Y9-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea70e744-a7a4-43f2-df03-0e49a55f26ac"
      },
      "source": [
        "# Detect hardware\n",
        "try:\n",
        "    tpu_resolver = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "except ValueError:\n",
        "    tpu_resolver = None\n",
        "    gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
        "\n",
        "# Select appropriate distribution strategy\n",
        "if tpu_resolver:\n",
        "    tf.config.experimental_connect_to_cluster(tpu_resolver)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu_resolver)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu_resolver)\n",
        "    print('Running on TPU ', tpu_resolver.cluster_spec().as_dict()['worker'])\n",
        "elif len(gpus) > 1:\n",
        "    strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\n",
        "    print('Running on multiple GPUs ', [gpu.name for gpu in gpus])\n",
        "elif len(gpus) == 1:\n",
        "    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "    print('Running on single GPU ', gpus[0].name)\n",
        "else:\n",
        "    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "    print('Running on CPU')\n",
        "  \n",
        "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.18.250.210:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.18.250.210:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on TPU  ['10.18.250.210:8470']\n",
            "Number of accelerators:  8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSN8UPU5LJ2m"
      },
      "source": [
        "logging.getLogger('tensorflow').setLevel(logging.ERROR)  # suppress warnings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qi1i-ctDxf9q"
      },
      "source": [
        "Clone the project repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "194Ce-5TXyOk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ea0261f-3703-4fd1-dc1c-b9953a5ccdbc"
      },
      "source": [
        "!git clone \"https://github.com/nikodallanoce/HLT/\"  # clone the project repository"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'HLT' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jPzw3JgkVVz"
      },
      "source": [
        "Mount the drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ANso0YFV4bx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67ceffee-d733-4d01-98f7-6655020f9111"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  # mount the drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxtaUqM2xyS0"
      },
      "source": [
        "Import all the models needed for the project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwcZtjXy5BA5"
      },
      "source": [
        "def create_encoder_bert():\n",
        "    with strategy.scope():\n",
        "        bert_model = TFBertModel.from_pretrained(\"bert-base-cased\")\n",
        "    return bert_model\n",
        "\n",
        "def create_encoder_distilbert():\n",
        "    with strategy.scope():\n",
        "        distilbert_model = TFDistilBertModel.from_pretrained(\"distilbert-base-cased\")\n",
        "    return distilbert_model\n",
        "\n",
        "def create_encoder_roberta():\n",
        "    with strategy.scope():\n",
        "        roberta_model = TFRobertaModel.from_pretrained(\"roberta-base\")\n",
        "    return roberta_model\n",
        "\n",
        "def create_encoder_t5():\n",
        "    with strategy.scope():\n",
        "        t5_model = TFT5EncoderModel.from_pretrained(\"google/t5-v1_1-base\")\n",
        "    return t5_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxerVzMD_EOD"
      },
      "source": [
        "from transformers import BertTokenizer, BertTokenizerFast, TFBertModel, DistilBertTokenizer, DistilBertTokenizerFast, TFDistilBertModel, RobertaTokenizerFast, RobertaTokenizer, TFRobertaModel, T5TokenizerFast, T5Tokenizer, TFT5EncoderModel\n",
        "\n",
        "logging.getLogger(\"transformers\").setLevel(logging.ERROR)  # suppress warning for transformers\n",
        "\n",
        "encoder_models = {\n",
        "    \"bert\": {\n",
        "        \"tokenizer\": BertTokenizerFast.from_pretrained(\"bert-base-cased\"),\n",
        "        \"encoder\": create_encoder_bert,\n",
        "        \"tokenizer_translation\": BertTokenizer.from_pretrained(\"bert-base-cased\"),\n",
        "    },\n",
        "    \"distilbert\": {\n",
        "        \"tokenizer\": DistilBertTokenizerFast.from_pretrained(\"distilbert-base-cased\"),\n",
        "        \"encoder\": create_encoder_distilbert,\n",
        "        \"tokenizer_translation\": DistilBertTokenizer.from_pretrained(\"distilbert-base-cased\"),\n",
        "    },\n",
        "    \"roberta\" : {\n",
        "        \"tokenizer\" : RobertaTokenizerFast.from_pretrained(\"roberta-base\"),\n",
        "        \"encoder\" : create_encoder_roberta,\n",
        "        \"tokenizer_translation\" : RobertaTokenizer.from_pretrained(\"roberta-base\"),\n",
        "    },\n",
        "    \"t5\": {\n",
        "        \"tokenizer\": T5TokenizerFast.from_pretrained(\"google/t5-v1_1-base\"),\n",
        "        \"encoder\" : create_encoder_t5,\n",
        "        \"tokenizer_translation\" : T5Tokenizer.from_pretrained(\"google/t5-v1_1-base\"),\n",
        "    },\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxDWi1wVWzyn"
      },
      "source": [
        "## **Building the training, validation and test set**\n",
        "\n",
        "We need to build our three sets by preprocessing the en-it anki dataset, tokenizing it and splitting it into training, validation and test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyCr1wXRZM29"
      },
      "source": [
        "### **Preprocessing the dataset**\n",
        "\n",
        "Create two lists containing the sentences of the anki dataset, one in english and one in italian."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC2VjPj2LzhY"
      },
      "source": [
        "Let's define the method to preprocess the anki dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfG1lSnbLZyl"
      },
      "source": [
        "def create_dataset_euparl(name: str, src: str = \"en\", dst: str = \"it\", size: float = 1) -> (list, list):\n",
        "    with open(name+\".{0}\".format(src), encoding=\"UTF-8\") as datafile:\n",
        "        src_set = datafile.readlines()\n",
        "\n",
        "    with open(name+\".{0}\".format(dst), encoding=\"UTF-8\") as datafile:\n",
        "        dst_set = datafile.readlines()\n",
        "\n",
        "    if size != 1:\n",
        "        if size > 1 or size < 0:\n",
        "            raise ValueError(\"No correct size for the euparl corpus\")\n",
        "        \n",
        "        datasets_to_shuffle = list((zip(src_set, dst_set)))\n",
        "        np.random.shuffle(datasets_to_shuffle)\n",
        "        src_set, dst_set = zip(*datasets_to_shuffle)\n",
        "        src_set = list(src_set[:int(len(src_set) * size)])\n",
        "        dst_set = list(dst_set[:int(len(dst_set) * size)])\n",
        "\n",
        "    return src_set, dst_set\n",
        "\n",
        "def create_dataset_anki(name: str, preprocessed:bool) -> (list, list):\n",
        "    with open(name, encoding=\"UTF-8\") as datafile:\n",
        "        src_set = list()\n",
        "        dst_set = list()\n",
        "        for sentence in datafile:\n",
        "            sentence = sentence.split(\"\\t\")\n",
        "            src_set.append(sentence[0])\n",
        "            if preprocessed:\n",
        "                dst_set.append(sentence[1].split(\"\\n\")[0])\n",
        "            else:\n",
        "                dst_set.append(sentence[1])\n",
        "\n",
        "    return src_set, dst_set\n",
        "\n",
        "def merge_datasets(first_dataset, second_dataset) -> (list, list):\n",
        "    first_src, first_dst = first_dataset\n",
        "    second_src, second_dst = second_dataset\n",
        "    src_set = first_src + second_src\n",
        "    dst_set = first_dst + second_dst\n",
        "    return src_set, dst_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgPVmTY7L6Tf"
      },
      "source": [
        "The dataset is in the project repository inside a zip file, we need to extract it and then we can build our lists using the previous method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKR-M38Duabq"
      },
      "source": [
        "fname = \"/content/drive/Shareddrives/HLT/datasets/it-en.tar\"\n",
        "tar = tarfile.open(fname, \"r:\")\n",
        "tar.extractall()\n",
        "tar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gamUp8XiLrwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3d42d82-8c9a-4889-b9c0-39e76c5d327c"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"HLT/dataset/dataset_anki_it.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"\")\n",
        "\n",
        "en_set_anki, it_set_anki = create_dataset_anki(\"ita_preprocessed.txt\", True)\n",
        "en_set_euparl, it_set_euparl = create_dataset_euparl(\"europarl-v7.it-en\", size=0.2)\n",
        "en_set, it_set = merge_datasets((en_set_anki, it_set_anki), (en_set_euparl, it_set_euparl))\n",
        "print(\"The corpus' size is: {0}\".format(len(en_set)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The corpus' size is: 733863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxl9EoWsZaUp"
      },
      "source": [
        "### **Dataset tokenization**\n",
        "\n",
        "We tokenize each sentence in the two lists by using the tokenizers from huggingface."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUn2kITYNVa3"
      },
      "source": [
        "Before we create the dataset from our lists, we have to tokenize each sentence from the corpus by using the BERT tokenizer for english and the one for italian. Moreover we can get the number of tokens for both source and target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6Mh4HYUTZXX"
      },
      "source": [
        "encoder_model = encoder_models[\"t5\"]\n",
        "ita_src = \"dbmdz/bert-base-italian-cased\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7r7wQatNVDs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e67d016-88ab-4386-d5e4-3d0809833b9d"
      },
      "source": [
        "# Create the tokenizers and get the number of tokens\n",
        "tokenizer_en = encoder_model[\"tokenizer\"]\n",
        "tokenizer_it = BertTokenizerFast.from_pretrained(ita_src)\n",
        "v_size_en = tokenizer_en.vocab_size\n",
        "v_size_it = tokenizer_it.vocab_size\n",
        "\n",
        "print(\"Number of tokens for the english dataset: {0}\".format(v_size_en))\n",
        "print(\"Number of tokens for the italian dataset: {0}\".format(v_size_it))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tokens for the english dataset: 32100\n",
            "Number of tokens for the italian dataset: 31102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Unwl54h9PSxV"
      },
      "source": [
        "Let's calculate the max number of tokens allowed, this number is taken such that 99% of the sentences in the dataset are fully tokenized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOTXTbSAIR_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "affc76fe-1f7a-4911-cb8c-3d63e6130f76"
      },
      "source": [
        "def set_max_tokens(dataset: list, language: str = \"en\") -> int:\n",
        "    len_sentences = [len(sentence.split()) for sentence in dataset]\n",
        "    mean_len_sentences = np.mean(len_sentences)\n",
        "    print(\"{0} dataset average sentence length: {1}\".format(language, mean_len_sentences))\n",
        "    max_length = int(mean_len_sentences + 2 * np.std(len_sentences))\n",
        "    print(\"{0} dataset max length allowed: {1}\".format(language, max_length))\n",
        "    return max_length\n",
        "\n",
        "max_length_en = set_max_tokens(en_set, \"en\")\n",
        "max_length_it = set_max_tokens(it_set, \"it\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "en dataset average sentence length: 16.215161412961276\n",
            "en dataset max length allowed: 46\n",
            "it dataset average sentence length: 15.667628699089612\n",
            "it dataset max length allowed: 45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0iDT4uDRdIA"
      },
      "source": [
        "Tokenize the source and target dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdfUZv0YOL1I"
      },
      "source": [
        "# Tokenize the dataset\n",
        "# max_length = np.max([max_length_en, max_length_it])  # use just one of the max length allowed\n",
        "max_length = 80\n",
        "with strategy.scope():\n",
        "    tokens_en = tokenizer_en(en_set, add_special_tokens=True, truncation=True, padding=\"max_length\",\n",
        "                              return_tensors=\"tf\", max_length=max_length).data[\"input_ids\"]\n",
        "    tokens_it = tokenizer_it(it_set, add_special_tokens=True, truncation=True, padding=\"max_length\",\n",
        "                              return_tensors=\"tf\", max_length=max_length+1).data[\"input_ids\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kltm2C_GcUrf"
      },
      "source": [
        "Let's show some sentences from both languages and how they were tokenized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t24nGn3-PhfB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4255acc-e503-452a-ef8d-9395e615fdbe"
      },
      "source": [
        "for _ in range(3):\n",
        "  i = np.random.randint(len(tokens_en))\n",
        "  print(\"En sentence: {0}\\nTokenized sentence: {1}\".format(en_set[i], tokens_en[i]))\n",
        "  print(\"It sentence: {0}\\nTokenized sentence: {1}\\n\".format(it_set[i], tokens_it[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "En sentence: Mr President, honourable Members. I should like to start by thanking the rapporteur, Mr Pérez Royo, for his report on the new fisheries protocol with the Comoros.\n",
            "\n",
            "Tokenized sentence: [ 1363  1661     6 14950   179  9537     5    27   225   114    12   456\n",
            "    57  2763    53     8  5346  1238     6  1363   276   154  2638 15875\n",
            "    32     6    21   112   934    30     8   126  2495  4074     7 10015\n",
            "    28     8  2570    32  1859     5     3     1     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0]\n",
            "It sentence: Signor Presidente, onorevoli parlamentari, desidero innanzitutto ringraziare l'onorevole Pérez Royo per la relazione sul nuovo protocollo di pesca con la Repubblica federale islamica delle Comore.\n",
            "\n",
            "Tokenized sentence: [  102  2227  1672  1307  8041 11793  1307 10253 14655 10747   181  1553\n",
            "  9023 24970 21664  7063 30879   156   146  1602   340   994  6063   120\n",
            "  2860   153   146  2521  6783 26707   324 14416   113   697   103     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0]\n",
            "\n",
            "En sentence: Don't you want to see Tom's paintings?\n",
            "Tokenized sentence: [1008   31   17   25  241   12  217 3059   31    7 9843   58    1    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0]\n",
            "It sentence: Non vuoi vedere i dipinti di Tom?\n",
            "Tokenized sentence: [  102   313  1634  1513   134 11405   120  4024  3098   103     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0]\n",
            "\n",
            "En sentence: I'm still busy.\n",
            "Tokenized sentence: [  27   31   51  341 3164    5    1    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0]\n",
            "It sentence: Io sono ancora impegnata.\n",
            "Tokenized sentence: [  102  1111   288   710 12737   697   103     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2dwetveOqdO"
      },
      "source": [
        "### **Splitting the dataset**\n",
        "\n",
        "Then we build the tf dataset and split it into training, validation and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZDQBwuPOxEU"
      },
      "source": [
        "def split_set(dataset: tf.data.Dataset,\n",
        "              tr: float = 0.8,\n",
        "              val: float = 0.1,\n",
        "              ts: float = 0.1,\n",
        "              shuffle: bool = True) -> (tf.data.Dataset, tf.data.Dataset, tf.data.Dataset):\n",
        "    if tr+val+ts != 1:\n",
        "        raise ValueError(\"Train, validation and test partition not allowed with such splits\")\n",
        "\n",
        "    dataset_size = dataset.cardinality().numpy()\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(dataset_size)\n",
        "\n",
        "    tr_size = int(tr * dataset_size)\n",
        "    val_size = int(val * dataset_size)\n",
        "\n",
        "    tr_set = dataset.take(tr_size)\n",
        "    val_set = dataset.skip(tr_size).take(val_size)\n",
        "    ts_set = dataset.skip(tr_size).skip(val_size)\n",
        "    return tr_set, val_set, ts_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uc8054ACO3Zh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a044f643-f9d8-4e00-924b-1086d3bbbe00"
      },
      "source": [
        "# Build the dataset and split it in train, validation and test\n",
        "dataset = tf.data.Dataset.from_tensor_slices((tokens_en, tokens_it))  # build the tf dataset\n",
        "tr_set, val_set, ts_set = split_set(dataset, 0.8, 0.1, 0.1)  # split the tf dataset\n",
        "print(\"Training set size: {0}\".format(len(tr_set)))\n",
        "print(\"Validation set size: {0}\".format(len(val_set)))\n",
        "print(\"Test set size: {0}\".format(len(ts_set)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 587090\n",
            "Validation set size: 73386\n",
            "Test set size: 73387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wrYPjy1dxwB"
      },
      "source": [
        "### **Create training and validation batches**\n",
        "\n",
        "After we have built our development and test set, we need to split the first one (both training and validation) in batches.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOiUgmSVPK1H"
      },
      "source": [
        "def format_dataset(eng, ita):\n",
        "    return ({\"encoder_inputs\": eng, \"decoder_inputs\": ita[:, :-1],}, ita[:, 1:])\n",
        "\n",
        "def make_batches(dataset_src_dst: tf.data.Dataset, batch_size: int) -> tf.data.Dataset:\n",
        "    dataset = dataset_src_dst.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.prefetch(tf.data.experimental.AUTOTUNE).cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hkK5H8iPNqj"
      },
      "source": [
        "batch_size =  16 * strategy.num_replicas_in_sync\n",
        "\n",
        "with strategy.scope():\n",
        "    tr_batches = make_batches(tr_set, batch_size)\n",
        "    val_batches = make_batches(val_set, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiDUbIoFwajW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db4dd634-11ba-4d3a-a56f-0bd50275c241"
      },
      "source": [
        "for src, dst in tr_batches.take(1):\n",
        "    print(\"encoder inputs shape: {0}\".format(src[\"encoder_inputs\"].shape))\n",
        "    print(\"decoder inputs shape: {0}\".format(src[\"decoder_inputs\"].shape))\n",
        "    print(\"targets shape: {0}\".format(dst.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder inputs shape: (128, 80)\n",
            "decoder inputs shape: (128, 80)\n",
            "targets shape: (128, 80)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iZAS6kYsWWR"
      },
      "source": [
        "## **Layers**\n",
        "\n",
        "Our sequence-to-sequence Transformer consists of a `TransformerEncoder`\n",
        "and a `TransformerDecoder` chained together."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNH_DBR_Fwn0"
      },
      "source": [
        "### **Positional embeddings layer**\n",
        "\n",
        "To make the model aware of word order, we also use a PositionalEmbedding layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfdbcMIgF4IU"
      },
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, v_size, embed_dim, **kwargs):\n",
        "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=v_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.v_size = v_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZdCgcJpR11c"
      },
      "source": [
        "### **Encoder**\n",
        "\n",
        "The source sequence will be pass to the TransformerEncoder, which will produce a new representation of it. This new representation will then be passed to the TransformerDecoder, together with the target sequence so far (target words 0 to N). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43KG2XY8kiOT"
      },
      "source": [
        "The single layer of the encoder transformer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWOzO7bDR8dU"
      },
      "source": [
        "class EncoderLayer(layers.Layer):\n",
        "\n",
        "    def __init__(self, layers_size: int, dense_size: int, num_heads: int, dropout=0.1, **kwargs) -> None:\n",
        "        super(EncoderLayer, self).__init__(**kwargs)\n",
        "        \n",
        "        self.layers_size = layers_size\n",
        "        self.dense_size = dense_size\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(num_heads, layers_size, dropout=dropout)\n",
        "        self.dense_proj = tf.keras.Sequential(\n",
        "            [layers.Dense(dense_size, activation=\"relu\"), layers.Dropout(dropout), layers.Dense(layers_size)]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs: tf.Tensor, mask=None) -> tf.Tensor:\n",
        "        if mask is not None:  \n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
        "        else:\n",
        "            print(\"Mask not built\")\n",
        "            assert False\n",
        "        \n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsq3swcQfwki"
      },
      "source": [
        "The encoder transformer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVU-JlJ6SB9x"
      },
      "source": [
        "class EncoderTransformer(layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_layers: int,\n",
        "                 layers_size: int,\n",
        "                 dense_size: int,\n",
        "                 num_heads: int,\n",
        "                 max_length: int,\n",
        "                 v_size_src: int,\n",
        "                 dropout: float = 0.1) -> None:\n",
        "        super(EncoderTransformer, self).__init__()\n",
        "\n",
        "        self.layers_size = layers_size\n",
        "        self.num_layers = num_layers\n",
        "        self.pos_embedding = PositionalEmbedding(max_length, v_size_src, layers_size)\n",
        "        self.enc_layers = [EncoderLayer(layers_size, dense_size, num_heads) for _ in range(num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs: tf.Tensor, mask=None) -> tf.Tensor:\n",
        "        src_embeddings = self.pos_embedding(inputs)\n",
        "        enc_out = self.dropout(src_embeddings)\n",
        "        for i in range(self.num_layers):\n",
        "            enc_out = self.enc_layers[i](enc_out)\n",
        "\n",
        "        return enc_out  # (batch_size, input_seq_len, layers_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk5x1zELSFyl"
      },
      "source": [
        "### **Decoder**\n",
        "\n",
        "The `TransformerDecoder` will then seek to predict the next words in the target sequence (N+1 and beyond)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WwlG430kpb7"
      },
      "source": [
        "The single layer of the decoder transformer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVmDmBHsSLHo"
      },
      "source": [
        "class DecoderLayer(layers.Layer):\n",
        "\n",
        "    def __init__(self, layers_size: int, dense_size: int, num_heads: int, dropout=0.1, **kwargs) -> None:\n",
        "        super(DecoderLayer, self).__init__(**kwargs)\n",
        "        \n",
        "        self.layers_size = layers_size\n",
        "        self.dense_size = dense_size\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(num_heads, layers_size, dropout=dropout)\n",
        "        self.attention_2 = layers.MultiHeadAttention(num_heads, layers_size, dropout=dropout)\n",
        "        self.dense_proj = tf.keras.Sequential(\n",
        "            [layers.Dense(dense_size, activation=\"relu\"), layers.Dropout(dropout), layers.Dense(layers_size)]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs: tf.Tensor, encoder_outputs: tf.Tensor, mask=None) -> tf.Tensor:\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
        "            axis=0,\n",
        "        )\n",
        "        return tf.tile(mask, mult)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8Rbdke8f17x"
      },
      "source": [
        "The decoder transformer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFQJbb3nSwhV"
      },
      "source": [
        "class DecoderTransformer(layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_layers: int,\n",
        "                 layers_size: int,\n",
        "                 dense_size: int,\n",
        "                 num_heads: int,\n",
        "                 max_length: int,\n",
        "                 v_size_dst: int,\n",
        "                 dropout=0.1) -> None:\n",
        "        super(DecoderTransformer, self).__init__()\n",
        "\n",
        "        self.layers_size = layers_size\n",
        "        self.num_layers = num_layers\n",
        "        self.pos_embedding = PositionalEmbedding(max_length, v_size_dst, layers_size)\n",
        "        self.dec_layers = [DecoderLayer(layers_size, dense_size, num_heads) for _ in range(num_layers)]\n",
        "        self.dropout = layers.Dropout(dropout)\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs: tf.Tensor, enc_output: tf.Tensor, mask=None) -> tf.Tensor:\n",
        "        dst_embeddings = self.pos_embedding(inputs)\n",
        "        dec_output = self.dropout(dst_embeddings)\n",
        "        for i in range(self.num_layers):\n",
        "            dec_output = self.dec_layers[i](dec_output, enc_output)\n",
        "\n",
        "        return dec_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWAPsdSfsWWS"
      },
      "source": [
        "## **Building the model**\n",
        "\n",
        "Next, we assemble the end-to-end model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SUtqG1Wik3L"
      },
      "source": [
        "with strategy.scope():\n",
        "    encoder = encoder_model[\"encoder\"]()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omRwwkoqJd6O"
      },
      "source": [
        "def create_model(layers_size: int, num_layers: int, dense_size: int, num_heads: int, max_length: int, encoder=None) -> tf.keras.Model:\n",
        "    # Encoder\n",
        "    encoder_inputs = tf.keras.Input(shape=(None,), dtype=\"int32\", name=\"encoder_inputs\")\n",
        "    if encoder is not None: \n",
        "        outputs = encoder(encoder_inputs)\n",
        "        encoder_outputs = outputs.last_hidden_state\n",
        "        layers_size = encoder_outputs.shape[-1]  # the size of the encoder and decoder layers must be the same\n",
        "    else:\n",
        "        encoder_outputs = EncoderTransformer(num_layers, layers_size, dense_size, num_heads, max_length, v_size_en)(encoder_inputs)\n",
        "\n",
        "    # Decoder\n",
        "    decoder_inputs = tf.keras.Input(shape=(None,), dtype=\"int32\", name=\"decoder_inputs\")\n",
        "    encoded_seq_inputs = tf.keras.Input(shape=(None, layers_size), name=\"decoder_state_inputs\")\n",
        "    decoder_outputs = DecoderTransformer(num_layers, layers_size, dense_size, num_heads, max_length, v_size_it)(decoder_inputs, encoded_seq_inputs)\n",
        "    decoder_outputs = layers.Dense(v_size_it, activation=\"softmax\")(decoder_outputs)\n",
        "    decoder = tf.keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "    # Final model\n",
        "    decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "    transformer = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\")\n",
        "    return transformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBji4C_qmXg-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fce432cc-55a6-44ff-8583-4e801c1a939e"
      },
      "source": [
        "with strategy.scope():\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
        "    transformer = create_model(512, 7, 2048, 8, 80, encoder)\n",
        "    transformer.summary()\n",
        "    transformer.compile(opt, loss = \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " tft5_encoder_model (TFT5Encode  TFBaseModelOutput(l  109628544  ['encoder_inputs[0][0]']         \n",
            " rModel)                        ast_hidden_state=(N                                               \n",
            "                                one, None, 768),                                                  \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " model (Functional)             (None, None, 31102)  334447230   ['decoder_inputs[0][0]',         \n",
            "                                                                  'tft5_encoder_model[0][0]']     \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 444,075,774\n",
            "Trainable params: 444,075,774\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mad4pECqsWWS"
      },
      "source": [
        "## **Training the model**\n",
        "\n",
        "We'll use accuracy as a quick way to monitor training progress on the validation data.\n",
        "Note that machine translation typically uses BLEU scores as well as other metrics, rather than accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGqZaPCi3mqU"
      },
      "source": [
        "with strategy.scope():\n",
        "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath='./t5_20.h5', save_weights_only = True, monitor='val_loss', mode='auto', save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VR8fzpHEsWWS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7341dfe9-3785-43bd-c975-f461b2dd3b7b"
      },
      "source": [
        "epochs = 10  # This should be at least 30 for convergence\n",
        "transformer.fit(tr_batches, epochs=epochs, validation_data = val_batches, callbacks=[model_checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond/Identity:0' shape=(None, 80) dtype=int32>, <tf.Tensor 'cond/Identity_8:0' shape=(None, 80) dtype=int32>, <tf.Tensor 'cond/Identity_16:0' shape=(None, 80) dtype=int32>]\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond/Identity:0' shape=(None, 80) dtype=int32>, <tf.Tensor 'cond/Identity_8:0' shape=(None, 80) dtype=int32>, <tf.Tensor 'cond/Identity_16:0' shape=(None, 80) dtype=int32>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4587/4587 [==============================] - ETA: 0s - loss: 0.8916 - accuracy: 0.4347"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond/Identity:0' shape=(None, 80) dtype=int32>, <tf.Tensor 'cond/Identity_8:0' shape=(None, 80) dtype=int32>, <tf.Tensor 'cond/Identity_16:0' shape=(None, 80) dtype=int32>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4587/4587 [==============================] - 2565s 527ms/step - loss: 0.8916 - accuracy: 0.4347 - val_loss: 0.5525 - val_accuracy: 0.5857\n",
            "Epoch 2/10\n",
            "4587/4587 [==============================] - 2295s 500ms/step - loss: 0.5254 - accuracy: 0.5981 - val_loss: 0.4216 - val_accuracy: 0.6602\n",
            "Epoch 3/10\n",
            "4587/4587 [==============================] - 2293s 500ms/step - loss: 0.4386 - accuracy: 0.6462 - val_loss: 0.3688 - val_accuracy: 0.6912\n",
            "Epoch 4/10\n",
            "4587/4587 [==============================] - 2304s 502ms/step - loss: 0.3930 - accuracy: 0.6722 - val_loss: 0.3365 - val_accuracy: 0.7105\n",
            "Epoch 5/10\n",
            "4587/4587 [==============================] - 2297s 501ms/step - loss: 0.3621 - accuracy: 0.6901 - val_loss: 0.3126 - val_accuracy: 0.7254\n",
            "Epoch 6/10\n",
            "4587/4587 [==============================] - 2296s 501ms/step - loss: 0.3384 - accuracy: 0.7039 - val_loss: 0.2954 - val_accuracy: 0.7369\n",
            "Epoch 7/10\n",
            "4587/4587 [==============================] - 2295s 500ms/step - loss: 0.3188 - accuracy: 0.7156 - val_loss: 0.2806 - val_accuracy: 0.7463\n",
            "Epoch 8/10\n",
            "4587/4587 [==============================] - 2298s 501ms/step - loss: 0.3019 - accuracy: 0.7258 - val_loss: 0.2675 - val_accuracy: 0.7556\n",
            "Epoch 9/10\n",
            "4587/4587 [==============================] - 2292s 500ms/step - loss: 0.2869 - accuracy: 0.7351 - val_loss: 0.2567 - val_accuracy: 0.7635\n",
            "Epoch 10/10\n",
            "4587/4587 [==============================] - 2297s 501ms/step - loss: 0.2734 - accuracy: 0.7436 - val_loss: 0.2471 - val_accuracy: 0.7706\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2c66682d90>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOvr3NkVg1Pi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82d7e8a9-22d4-48e6-9da8-fc35f444c8a1"
      },
      "source": [
        "ts_loss, ts_accuracy = transformer.evaluate(make_batches(ts_set, batch_size))\n",
        "print(\"Test loss: {0}\\nTest accuracy: {1}\".format(ts_loss, ts_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "574/574 [==============================] - 59s 96ms/step - loss: 0.2471 - accuracy: 0.7707\n",
            "Test loss: 0.24705299735069275\n",
            "Test accuracy: 0.7706549167633057\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEdpAMpbVLou",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "ead892cc-f233-4c63-98ce-6ec567ddcc07"
      },
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    transformer, to_file='base.png', show_shapes=True, dpi=90\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bw_Et-rpJKuC"
      },
      "source": [
        "transformer.save_weights('/content/drive/Shareddrives/HLT/models/t5_20.h5', overwrite=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj4TsHwysWWS"
      },
      "source": [
        "## **Translator**\n",
        "\n",
        "Build the translator which implements all the methods needed to translate sentence from language to another."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZtPZMFHU3Sn"
      },
      "source": [
        "tokenizer_it = BertTokenizer.from_pretrained(ita_src)\n",
        "with strategy.scope():\n",
        "  transformer = create_model(512, 6, 2048, 8, 80)\n",
        "  transformer.load_weights('/content/drive/Shareddrives/HLT/models/base.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiB9dW8VsWWS"
      },
      "source": [
        "class Translator(tf.Module):\n",
        "\n",
        "    def __init__(self, tokenizer_src, tokenizer_dst, max_length: int, transformer: tf.keras.Model) -> None:\n",
        "        super(Translator, self).__init__()\n",
        "        self.tokenizer_src = tokenizer_src\n",
        "        self.tokenizer_dst = tokenizer_dst\n",
        "        self.max_length = max_length\n",
        "        self.transformer = transformer\n",
        "\n",
        "    def translate(self, input_sentence: str, k: int = 1) -> (list, str):\n",
        "        tokenized_input_sentence = self.tokenizer_src(input_sentence, return_tensors='tf', add_special_tokens=True,\n",
        "                                                      max_length=self.max_length, padding='max_length',\n",
        "                                                      truncation=True).data[\"input_ids\"]\n",
        "        decoded_sentence = \"[CLS]\"\n",
        "        list_tokens = [decoded_sentence]\n",
        "        for i in range(self.max_length):\n",
        "            decoded_sentence = self.tokenizer_dst.convert_tokens_to_string(list_tokens)\n",
        "            tokenized_dst_sentence = self.tokenizer_dst(decoded_sentence, return_tensors='tf', add_special_tokens=False,\n",
        "                                                        max_length=self.max_length,\n",
        "                                                        padding='max_length', truncation=True).data['input_ids']\n",
        "            predictions = self.transformer([tokenized_input_sentence, tokenized_dst_sentence])\n",
        "            sampled_token_indexes = np.argsort(predictions[0, i, :])[-k:]\n",
        "            p = [float(predictions[0, i, j]) for j in sampled_token_indexes]\n",
        "            p = np.array(p)\n",
        "            p /= np.sum(p)\n",
        "            sampled_token_index = np.random.choice(sampled_token_indexes, 1, p=p)\n",
        "            sampled_token = self.tokenizer_dst.ids_to_tokens[sampled_token_index[0]]\n",
        "            # print(sampled_token)\n",
        "            if sampled_token == \"[SEP]\":\n",
        "                decoded_sentence = self.tokenizer_dst.convert_tokens_to_string(list_tokens[1:])\n",
        "                break\n",
        "\n",
        "            list_tokens.append(sampled_token)\n",
        "\n",
        "        return list_tokens, decoded_sentence\n",
        "    \n",
        "    def translate_beam_search(self, input_sentence: str, k=2):\n",
        "        tokenized_input_sentence = self.tokenizer_src(input_sentence, return_tensors='tf', add_special_tokens=True, max_length=self.max_length,\n",
        "                          padding='max_length', truncation=True).data[\"input_ids\"]\n",
        "        decoded_sentence = ([\"[CLS]\"], 1)\n",
        "        beam_queue = SimpleQueue()\n",
        "        beam_queue.put(decoded_sentence)\n",
        "        translated = list()\n",
        "        i = 0\n",
        "        while not beam_queue.empty() and i < self.max_length:\n",
        "            tokenized_sentence, prb = beam_queue.get()\n",
        "            decoded_sentence = self.tokenizer_dst.convert_tokens_to_string(tokenized_sentence)\n",
        "            tokenized_target_sentence = self.tokenizer_dst(decoded_sentence, return_tensors='tf', add_special_tokens=False, max_length=self.max_length,\n",
        "                              padding='max_length').data['input_ids']\n",
        "            predictions = self.transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "            i = len(tokenized_sentence) - 1\n",
        "            sampled_token_indexes = np.argsort(predictions[0, i, :])[-k:]\n",
        "            probabilities = [float(predictions[0, i, j]) for j in sampled_token_indexes]\n",
        "            for samp_index, p in zip(sampled_token_indexes, probabilities):\n",
        "                sampled_token = self.tokenizer_dst.ids_to_tokens[samp_index]\n",
        "                tok_sent_with_new_samp = tokenized_sentence.copy()\n",
        "                tok_sent_with_new_samp.append(sampled_token)\n",
        "                next_sent = (tok_sent_with_new_samp, p * prb)\n",
        "                if sampled_token == \"[SEP]\":  # and next_sent[1] > 0.02:\n",
        "                    translated.append(next_sent)\n",
        "                elif next_sent[1] > 0.001:\n",
        "                    beam_queue.put(next_sent)\n",
        "\n",
        "        translated.sort(key=lambda x: x[1], reverse=True)\n",
        "        return translated\n",
        "  \n",
        "    def decode_sequence_beam_pruning(self, input_sentence, k=2, sequence_length=90):\n",
        "        tokenized_input_sentence = self.tokenizer_src(input_sentence, return_tensors='tf', add_special_tokens=True,\n",
        "                                                      max_length=sequence_length,\n",
        "                                                      padding='max_length', truncation=True).data[\"input_ids\"]\n",
        "        decoded_sentence = ([\"[CLS]\"], 1)\n",
        "        beam_queue = Queue(2 ** 8)\n",
        "        beam_queue.put(decoded_sentence)\n",
        "        translated = []\n",
        "        i = 0\n",
        "\n",
        "        while not beam_queue.empty() and i < sequence_length:\n",
        "            max_prob = 0\n",
        "            tokenized_sentence, prb = beam_queue.get()\n",
        "            decoded_sentence = self.tokenizer_dst.convert_tokens_to_string(tokenized_sentence)\n",
        "            tokenized_dst_sentence = self.tokenizer_dst(decoded_sentence, return_tensors='tf', add_special_tokens=False,\n",
        "                                                        max_length=sequence_length, truncation=True,\n",
        "                                                        padding='max_length').data['input_ids']\n",
        "            predictions = self.transformer([tokenized_input_sentence, tokenized_dst_sentence])\n",
        "            i = len(tokenized_sentence) - 1\n",
        "            sampled_token_indexes = np.flip(np.argsort(predictions[0, i, :])[-k:])\n",
        "            probabilities = [float(predictions[0, i, j]) for j in sampled_token_indexes]\n",
        "\n",
        "            for samp_index, p in zip(sampled_token_indexes, probabilities):\n",
        "                sampled_token = self.tokenizer_dst.ids_to_tokens[samp_index]\n",
        "                tok_sent_with_new_samp = tokenized_sentence.copy()\n",
        "                tok_sent_with_new_samp.append(sampled_token)\n",
        "                next_sent = (tok_sent_with_new_samp, p * prb)\n",
        "                if next_sent[1] > max_prob:\n",
        "                    max_prob = next_sent[1]\n",
        "\n",
        "                if sampled_token == \"[SEP]\":\n",
        "                    translated.append(next_sent)\n",
        "                    print([self.tokenizer_dst.convert_tokens_to_string(next_sent[0][1:-1]), next_sent[1]])\n",
        "\n",
        "                elif next_sent[1] > max_prob / 1.5:\n",
        "                    beam_queue.put(next_sent)\n",
        "\n",
        "            if len(translated) > 2:\n",
        "                break\n",
        "\n",
        "        translated.sort(key=lambda x: x[1], reverse=True)\n",
        "        return translated[0], self.tokenizer_dst.convert_tokens_to_string(translated[0][0][1:-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhBNEDomEfu-",
        "outputId": "dca7d7db-8e0a-4ea4-94b0-6d77d37ae3be"
      },
      "source": [
        "with strategy.scope():\n",
        "    translator = Translator(encoder_model[\"tokenizer_translation\"], BertTokenizer.from_pretrained(ita_src), 80, transformer)\n",
        "\n",
        "en = \"I ate a lion with my friend after we had dinner, it was delicious and we want to eat it again.\"\n",
        "out_translation = translator.translate(en)\n",
        "print(out_translation[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ho mangiato un leone con il mio amico dopo cena , che è delizioso e che vogliamo mangiare di nuovo .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szfzQibA8zl4"
      },
      "source": [
        "## **Bleu score**\n",
        "\n",
        "Evaluate the model by using the SacreBLEU score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkyp4eE6fkQV"
      },
      "source": [
        "import tarfile\n",
        "fname = \"/content/drive/Shareddrives/HLT/evaluation/flores101_dataset.tar.gz\"\n",
        "if fname.endswith(\"tar.gz\"):\n",
        "    tar = tarfile.open(fname, \"r:gz\")\n",
        "    tar.extractall()\n",
        "    tar.close()\n",
        "elif fname.endswith(\"tar\"):\n",
        "    tar = tarfile.open(fname, \"r:\")\n",
        "    tar.extractall()\n",
        "    tar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJeMhlrX1Cst"
      },
      "source": [
        "with open(\"/content/flores101_dataset/devtest/eng.devtest\", encoding=\"UTF-8\") as datafile:\n",
        "    src_test = list()\n",
        "    for sentence in datafile:\n",
        "        src_test.append(sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd9YAJtD2--K"
      },
      "source": [
        "tokenizer_it = BertTokenizer.from_pretrained(ita_src)\n",
        "with strategy.scope():\n",
        "    transformer = create_model(512, 6, 2048, 8, 80, TFT5EncoderModel.from_pretrained(\"google/t5-v1_1-small\"))\n",
        "    transformer.load_weights('drive/Shareddrives/HLT/t5v11small.h5')\n",
        "    # translator = Translator(encoder_model[\"tokenizer_translation\"], BertTokenizer.from_pretrained(ita_src), 80, transformer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394,
          "referenced_widgets": [
            "d91e88ca621440019973b14d249c8a6f",
            "60cd70bc8f1545f382c4c7b4ddc1a2a1",
            "a98414bdf3034c5396a91a4f10de5f73",
            "1f7accae7f2b4260a6820fa1b8924dbd",
            "8b64aee5b5c643638d74e37202d4690d",
            "bdfba53940b14ea8bd9dee7cfc2a5894",
            "233e1e8ba8514605a3d657266a63deb6",
            "801e9325caf641568ebb41c199e59522",
            "dd61a101c3ab49bbb66b7938fe92e2e9",
            "b53858517b7648acae24f4f1fbc60e1d",
            "d1976a46a44f4cc7b55e6a0c6fccadb3"
          ]
        },
        "id": "z2_M9rqu1rm-",
        "outputId": "785cc5d4-6404-4dfc-d4ff-b5b9b6d2588d"
      },
      "source": [
        "dst_out = list()\n",
        "for sentence in tqdm_notebook(src_test):\n",
        "    dst_out.append(translator.translate(sentence, k=5)[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d91e88ca621440019973b14d249c8a6f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1012 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-89e0938b2376>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdst_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdst_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-8a81b909ba6d>\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(self, input_sentence, k)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokenized_input_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenized_dst_sentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0msampled_token_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampled_token_indexes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-8a81b909ba6d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokenized_input_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenized_dst_sentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0msampled_token_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msampled_token_indexes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1051\u001b[0m         \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[1;32m   1223\u001b[0m       \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m       shrink_axis_mask=shrink_axis_mask)\n\u001b[0m\u001b[1;32m   1226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m   \u001b[0mparent_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[1;32m  10666\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"StridedSlice\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"begin_mask\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10667\u001b[0m         \u001b[0mbegin_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end_mask\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ellipsis_mask\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10668\u001b[0;31m         \"new_axis_mask\", new_axis_mask, \"shrink_axis_mask\", shrink_axis_mask)\n\u001b[0m\u001b[1;32m  10669\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10670\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aA3OQQu7zmL"
      },
      "source": [
        "with open(\"drive/Shareddrives/HLT/evaluation/translation_t5_sampling.txt\", \"w\", encoding=\"UTF-8\") as datafile:\n",
        "    for sentence in dst_out:\n",
        "        datafile.write(\"{0}\\n\".format(sentence))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3kuxV2XN2Sy"
      },
      "source": [
        "!git clone --single-branch --branch adding_spm_tokenized_bleu https://github.com/ngoyal2707/sacrebleu.git\n",
        "%cd sacrebleu\n",
        "!python setup.py install\n",
        "%cd ../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9HDlTlS7AqB"
      },
      "source": [
        "!cat drive/Shareddrives/HLT/evaluation/translation_t5_sampling.txt | sacrebleu -tok spm flores101_dataset/devtest/ita.devtest --force --score-only"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}