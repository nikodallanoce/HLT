{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "DallaNoce_Ristori_HLT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ZYveYZaAJ4CK",
        "eNH_DBR_Fwn0",
        "YX3K1uHFRyW9",
        "jZdCgcJpR11c",
        "Xk5x1zELSFyl",
        "n9z1wDY_JW43"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5gTl7VXJiwo"
      },
      "source": [
        "**Human Language Technologies Project**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmyUEYbqJqPs"
      },
      "source": [
        "**Authors:** Dalla Noce Niko, Ristori Alessandro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AKYoZs9jmP8"
      },
      "source": [
        "# **HLT Project**\n",
        "\n",
        "This work is higly based on the tensorflow tutorial https://www.tensorflow.org/text/tutorials/transformer, our aim was to introduce BERT as an encoder in the model and try combinations with different architectures (both RNNs and transformers)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztt9YLmZsWWM"
      },
      "source": [
        "## **Setup**\n",
        "We need to install the transformers package to use the models and tokenizers from HuggingFace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eHtucw_fBpQ",
        "outputId": "2bc240e6-f542-4049-a6d5-3e81d66b767d"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkjsPkIosWWM"
      },
      "source": [
        "import logging\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngtpmviRXGsX"
      },
      "source": [
        "The model training is going to run on TPUs since they are the optimized for working with tensors, if there are no TPUs avilable then we work with a GPU instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hd5zB1G7Y9-7",
        "outputId": "f3b44c2c-1e0c-4449-9559-74ab09fe4a7d"
      },
      "source": [
        "# Detect hardware\n",
        "try:\n",
        "    tpu_resolver = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "except ValueError:\n",
        "    tpu_resolver = None\n",
        "    gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
        "\n",
        "# Select appropriate distribution strategy\n",
        "if tpu_resolver:\n",
        "    tf.config.experimental_connect_to_cluster(tpu_resolver)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu_resolver)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu_resolver)\n",
        "    print('Running on TPU ', tpu_resolver.cluster_spec().as_dict()['worker'])\n",
        "elif len(gpus) > 1:\n",
        "    strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\n",
        "    print('Running on multiple GPUs ', [gpu.name for gpu in gpus])\n",
        "elif len(gpus) == 1:\n",
        "    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "    print('Running on single GPU ', gpus[0].name)\n",
        "else:\n",
        "    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "    print('Running on CPU')\n",
        "  \n",
        "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.10.40.90:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.10.40.90:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on TPU  ['10.10.40.90:8470']\n",
            "Number of accelerators:  8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSN8UPU5LJ2m"
      },
      "source": [
        "logging.getLogger('tensorflow').setLevel(logging.ERROR)  # suppress warnings"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "194Ce-5TXyOk",
        "outputId": "d5b8cbfc-711b-4846-b380-6be5e2d5bd60"
      },
      "source": [
        "!git clone \"https://github.com/nikodallanoce/HLT/\"  # clone the project repository"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'HLT' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxDWi1wVWzyn"
      },
      "source": [
        "## **Building the training, validation and test set**\n",
        "\n",
        "We need to build our three sets by preprocessing the en-it anki dataset, tokenizing it and splitting it into training, validation and test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyCr1wXRZM29"
      },
      "source": [
        "### **Preprocessing the dataset**\n",
        "\n",
        "Create two lists containing the sentences of the anki dataset, one in english and one in italian."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC2VjPj2LzhY"
      },
      "source": [
        "Let's define the method to preprocess the anki dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfG1lSnbLZyl"
      },
      "source": [
        "def create_dataset_anki(name: str, preprocessed:bool) -> (list, list):\n",
        "    with open(name, encoding=\"UTF-8\") as datafile:\n",
        "        src_set = list()\n",
        "        dst_set = list()\n",
        "        for sentence in datafile:\n",
        "            sentence = sentence.split(\"\\t\")\n",
        "            src_set.append(sentence[0])\n",
        "            if preprocessed:\n",
        "                dst_set.append(sentence[1].split(\"\\n\")[0])\n",
        "            else:\n",
        "                dst_set.append(sentence[1])\n",
        "\n",
        "    return src_set, dst_set"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgPVmTY7L6Tf"
      },
      "source": [
        "The dataset is in the project repository inside a zip file, we need to extract it and then we can build our lists using the previous method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gamUp8XiLrwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4ae4f3b-f945-43ba-8c38-db1bbc896db7"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"HLT/dataset/dataset_anki_it.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"\")\n",
        "\n",
        "en_set, it_set = create_dataset_anki(\"ita_preprocessed.txt\", True)\n",
        "print(\"The corpus' size is: {0}\".format(len(en_set)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The corpus' size is: 352040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxl9EoWsZaUp"
      },
      "source": [
        "### **Dataset tokenization**\n",
        "\n",
        "We tokenize each sentence in the two lists by using the tokenizers from huggingface."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUn2kITYNVa3"
      },
      "source": [
        "Before we create the dataset from our lists, we have to tokenize each sentence from the corpus by using the BERT tokenizer for english and the one for italian. Moreover we can get the number of tokens for both source and target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6Mh4HYUTZXX"
      },
      "source": [
        "eng_src = \"t5-base\"\n",
        "ita_src = \"dbmdz/bert-base-italian-cased\""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7r7wQatNVDs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3fb75ac-64a7-474a-de09-7dfb8e15f47e"
      },
      "source": [
        "from transformers import BertTokenizer, BertTokenizerFast, TFMT5EncoderModel, T5TokenizerFast, AutoTokenizer, XLMTokenizer, TFT5EncoderModel, DistilBertTokenizerFast, TFDistilBertModel\n",
        "\n",
        "logging.getLogger(\"transformers\").setLevel(logging.ERROR)  # suppress warning for transformers\n",
        "\n",
        "# Create the tokenizers and get the number of tokens\n",
        "tokenizer_en = T5TokenizerFast.from_pretrained(eng_src)\n",
        "tokenizer_it = BertTokenizerFast.from_pretrained(ita_src)\n",
        "v_size_en = tokenizer_en.vocab_size\n",
        "v_size_it = tokenizer_it.vocab_size\n",
        "\n",
        "print(\"Number of tokens for the english dataset: {0}\".format(v_size_en))\n",
        "print(\"Number of tokens for the italian dataset: {0}\".format(v_size_it))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tokens for the english dataset: 32100\n",
            "Number of tokens for the italian dataset: 31102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Unwl54h9PSxV"
      },
      "source": [
        "Let's calculate the max number of tokens allowed, this number is taken such that 99% of the sentences in the dataset are fully tokenized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOTXTbSAIR_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e640dc4-425c-4535-e823-230728aaf0f5"
      },
      "source": [
        "def set_max_tokens(dataset: list, language: str = \"en\") -> int:\n",
        "    len_sentences = [len(sentence.split()) for sentence in dataset]\n",
        "    mean_len_sentences = np.mean(len_sentences)\n",
        "    print(\"{0} dataset average sentence length: {1}\".format(language, mean_len_sentences))\n",
        "    max_length = int(mean_len_sentences + 3 * np.std(len_sentences))\n",
        "    print(\"{0} dataset max length allowed: {1}\".format(language, max_length))\n",
        "    return max_length\n",
        "\n",
        "max_length_en = set_max_tokens(en_set, \"en\")\n",
        "max_length_it = set_max_tokens(it_set, \"it\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "en dataset average sentence length: 5.492988603988604\n",
            "en dataset max length allowed: 11\n",
            "it dataset average sentence length: 5.35585754985755\n",
            "it dataset max length allowed: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0iDT4uDRdIA"
      },
      "source": [
        "Tokenize the source and target dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdfUZv0YOL1I"
      },
      "source": [
        "# Tokenize the dataset\n",
        "max_length = np.max([max_length_en, max_length_it]) * 2  # use just one of the max length allowed\n",
        "with strategy.scope():\n",
        "    tokens_en = tokenizer_en(en_set, add_special_tokens=True,\n",
        "                              truncation=True, padding=\"max_length\", return_attention_mask=True,\n",
        "                              return_tensors=\"tf\", max_length=max_length).data[\"input_ids\"]\n",
        "    tokens_it = tokenizer_it(it_set, add_special_tokens=True,\n",
        "                              truncation=True, padding=\"max_length\", return_attention_mask=True,\n",
        "                              return_tensors=\"tf\", max_length=max_length+1).data[\"input_ids\"]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kltm2C_GcUrf"
      },
      "source": [
        "Let's show some sentences from both languages and how they were tokenized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t24nGn3-PhfB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e24b812-ef3e-43be-9663-1e30077c8012"
      },
      "source": [
        "for _ in range(3):\n",
        "  i = np.random.randint(len(tokens_en))\n",
        "  print(\"En sentence: {0}\\nTokenized sentence: {1}\".format(en_set[i], tokens_en[i]))\n",
        "  print(\"It sentence: {0}\\nTokenized sentence: {1}\\n\".format(it_set[i], tokens_it[i]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "En sentence: Does Tom know what he's doing?\n",
            "Tokenized sentence: [3520 3059  214  125    3   88   31    7  692   58    1    0    0    0\n",
            "    0    0    0    0    0    0    0    0]\n",
            "It sentence: Tom sa quello che sta facendo?\n",
            "Tokenized sentence: [ 102 4024  352  678  158  244 1827 3098  103    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0]\n",
            "\n",
            "En sentence: I'm not as expert as you are.\n",
            "Tokenized sentence: [  27   31   51   59   38 2205   38   25   33    5    1    0    0    0\n",
            "    0    0    0    0    0    0    0    0]\n",
            "It sentence: Non sono esperto come te.\n",
            "Tokenized sentence: [  102   313   288 11241   342   294   697   103     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0]\n",
            "\n",
            "En sentence: Tom is keeping his promise.\n",
            "Tokenized sentence: [3059   19 2627  112 5712    5    1    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0]\n",
            "It sentence: Tom sta mantenendo la sua promessa.\n",
            "Tokenized sentence: [  102  4024   244 13971   146   497 10164   697   103     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2dwetveOqdO"
      },
      "source": [
        "### **Splitting the dataset**\n",
        "\n",
        "Then we build the tf dataset and split it into training, validation and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZDQBwuPOxEU"
      },
      "source": [
        "def split_set(dataset: tf.data.Dataset,\n",
        "              tr: float = 0.8,\n",
        "              val: float = 0.1,\n",
        "              ts: float = 0.1,\n",
        "              shuffle: bool = True) -> (tf.data.Dataset, tf.data.Dataset, tf.data.Dataset):\n",
        "    if tr+val+ts != 1:\n",
        "        raise ValueError(\"Train, validation and test partition not allowed with such splits\")\n",
        "\n",
        "    dataset_size = dataset.cardinality().numpy()\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(dataset_size)\n",
        "\n",
        "    tr_size = int(tr * dataset_size)\n",
        "    val_size = int(val * dataset_size)\n",
        "\n",
        "    tr_set = dataset.take(tr_size)\n",
        "    val_set = dataset.skip(tr_size).take(val_size)\n",
        "    ts_set = dataset.skip(tr_size).skip(val_size)\n",
        "    return tr_set, val_set, ts_set"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uc8054ACO3Zh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d79ed23-f2ce-4eef-858f-908ff6bad9ea"
      },
      "source": [
        "# Build the dataset and split it in train, validation and test\n",
        "dataset = tf.data.Dataset.from_tensor_slices((tokens_en, tokens_it))  # build the tf dataset\n",
        "tr_set, val_set, ts_set = split_set(dataset, 0.8, 0.1, 0.1)  # split the tf dataset\n",
        "print(\"Training set size: {0}\".format(len(tr_set)))\n",
        "print(\"Validation set size: {0}\".format(len(val_set)))\n",
        "print(\"Test set size: {0}\".format(len(ts_set)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 281632\n",
            "Validation set size: 35204\n",
            "Test set size: 35204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wrYPjy1dxwB"
      },
      "source": [
        "### **Create training and validation batches**\n",
        "\n",
        "After we have built our development and test set, we need to split the first one (both training and validation) in batches.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOiUgmSVPK1H"
      },
      "source": [
        "def format_dataset(eng, ita):\n",
        "    return ({\"encoder_inputs\": eng, \"decoder_inputs\": ita[:, :-1],}, ita[:, 1:])\n",
        "\n",
        "def make_batches(dataset_src_dst: tf.data.Dataset, batch_size: int) -> tf.data.Dataset:\n",
        "    dataset = dataset_src_dst.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.prefetch(tf.data.experimental.AUTOTUNE).cache()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hkK5H8iPNqj"
      },
      "source": [
        "batch_size =  16 * strategy.num_replicas_in_sync\n",
        "\n",
        "with strategy.scope():\n",
        "    tr_batches = make_batches(tr_set, batch_size)\n",
        "    val_batches = make_batches(val_set, batch_size)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiDUbIoFwajW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34982a5f-1b0e-494b-edeb-5304da2e48d7"
      },
      "source": [
        "for src, dst in tr_batches.take(1):\n",
        "    print(\"encoder inputs shape: {0}\".format(src[\"encoder_inputs\"].shape))\n",
        "    print(\"decoder inputs shape: {0}\".format(src[\"decoder_inputs\"].shape))\n",
        "    print(\"targets shape: {0}\".format(dst.shape))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder inputs shape: (128, 22)\n",
            "decoder inputs shape: (128, 22)\n",
            "targets shape: (128, 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iZAS6kYsWWR"
      },
      "source": [
        "## **Layers**\n",
        "\n",
        "Our sequence-to-sequence Transformer consists of a `TransformerEncoder`\n",
        "and a `TransformerDecoder` chained together."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNH_DBR_Fwn0"
      },
      "source": [
        "### **Positional embeddings layer**\n",
        "\n",
        "To make the model aware of word order, we also use a PositionalEmbedding layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfdbcMIgF4IU"
      },
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, v_size, embed_dim, **kwargs):\n",
        "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=v_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.v_size = v_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZdCgcJpR11c"
      },
      "source": [
        "### **Encoder**\n",
        "\n",
        "The source sequence will be pass to the TransformerEncoder, which will produce a new representation of it. This new representation will then be passed to the TransformerDecoder, together with the target sequence so far (target words 0 to N). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43KG2XY8kiOT"
      },
      "source": [
        "The single layer of the encoder transformer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWOzO7bDR8dU"
      },
      "source": [
        "class EncoderLayer(layers.Layer):\n",
        "\n",
        "    def __init__(self, layers_size: int, dense_size: int, num_heads: int, dropout=0.1, **kwargs) -> None:\n",
        "        super(EncoderLayer, self).__init__(**kwargs)\n",
        "        \n",
        "        self.layers_size = layers_size\n",
        "        self.dense_size = dense_size\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(num_heads, layers_size)\n",
        "        self.dense_proj = tf.keras.Sequential(\n",
        "            [layers.Dense(dense_size, activation=\"relu\"), layers.Dense(layers_size)]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.dropout_1 = layers.Dropout(dropout)\n",
        "        self.dropout_2 = layers.Dropout(dropout)\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs: tf.Tensor, mask=None) -> tf.Tensor:\n",
        "        if mask is not None:  \n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
        "        else:\n",
        "            print(\"Mask not built\")\n",
        "            assert False\n",
        "        \n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "        attention_output = self.dropout_1(attention_output)\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        proj_output = self.dropout_1(proj_output)\n",
        "        return self.layernorm_2(proj_input + proj_output)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsq3swcQfwki"
      },
      "source": [
        "The encoder transformer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVU-JlJ6SB9x"
      },
      "source": [
        "class EncoderTransformer(layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_layers: int,\n",
        "                 layers_size: int,\n",
        "                 dense_size: int,\n",
        "                 num_heads: int,\n",
        "                 max_length: int,\n",
        "                 v_size_src: int,\n",
        "                 dropout: float = 0.1) -> None:\n",
        "        super(EncoderTransformer, self).__init__()\n",
        "\n",
        "        self.layers_size = layers_size\n",
        "        self.num_layers = num_layers\n",
        "        self.pos_embedding = PositionalEmbedding(max_length, v_size_src, layers_size)\n",
        "        self.enc_layers = [EncoderLayer(layers_size, dense_size, num_heads) for _ in range(num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs: tf.Tensor, mask=None) -> tf.Tensor:\n",
        "        src_embeddings = self.pos_embedding(inputs)\n",
        "        enc_out = self.dropout(src_embeddings)\n",
        "        for i in range(self.num_layers):\n",
        "            enc_out = self.enc_layers[i](enc_out)\n",
        "\n",
        "        return enc_out  # (batch_size, input_seq_len, layers_size)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk5x1zELSFyl"
      },
      "source": [
        "### **Decoder**\n",
        "\n",
        "The `TransformerDecoder` will then seek to predict the next words in the target sequence (N+1 and beyond)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WwlG430kpb7"
      },
      "source": [
        "The single layer of the decoder transformer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVmDmBHsSLHo"
      },
      "source": [
        "class DecoderLayer(layers.Layer):\n",
        "\n",
        "    def __init__(self, layers_size: int, dense_size: int, num_heads: int, dropout=0.1, **kwargs) -> None:\n",
        "        super(DecoderLayer, self).__init__(**kwargs)\n",
        "        \n",
        "        self.layers_size = layers_size\n",
        "        self.dense_size = dense_size\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(num_heads, layers_size)\n",
        "        self.attention_2 = layers.MultiHeadAttention(num_heads, layers_size)\n",
        "        self.dense_proj = tf.keras.Sequential(\n",
        "            [layers.Dense(dense_size, activation=\"relu\"), layers.Dense(layers_size)]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.dropout_1 = layers.Dropout(dropout)\n",
        "        self.dropout_2 = layers.Dropout(dropout)\n",
        "        self.dropout_3 = layers.Dropout(dropout)\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs: tf.Tensor, encoder_outputs: tf.Tensor, mask=None) -> tf.Tensor:\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
        "        )\n",
        "        attention_output_1 = self.dropout_1(attention_output_1)\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        attention_output_2 = self.dropout_2(attention_output_2)\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        proj_output = self.dropout_3(proj_output)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
        "            axis=0,\n",
        "        )\n",
        "        return tf.tile(mask, mult)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8Rbdke8f17x"
      },
      "source": [
        "The decoder transformer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFQJbb3nSwhV"
      },
      "source": [
        "class DecoderTransformer(layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_layers: int,\n",
        "                 layers_size: int,\n",
        "                 dense_size: int,\n",
        "                 num_heads: int,\n",
        "                 max_length: int,\n",
        "                 v_size_dst: int,\n",
        "                 dropout=0.1) -> None:\n",
        "        super(DecoderTransformer, self).__init__()\n",
        "\n",
        "        self.layers_size = layers_size\n",
        "        self.num_layers = num_layers\n",
        "        self.pos_embedding = PositionalEmbedding(max_length, v_size_dst, layers_size)\n",
        "        self.dec_layers = [DecoderLayer(layers_size, dense_size, num_heads) for _ in range(num_layers)]\n",
        "        self.dropout = layers.Dropout(dropout)\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs: tf.Tensor, enc_output: tf.Tensor, mask=None) -> tf.Tensor:\n",
        "        dst_embeddings = self.pos_embedding(inputs)\n",
        "        dec_output = self.dropout(dst_embeddings)\n",
        "        for i in range(self.num_layers):\n",
        "            dec_output = self.dec_layers[i](dec_output, enc_output)\n",
        "\n",
        "        return dec_output"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWAPsdSfsWWS"
      },
      "source": [
        "## **Building the model**\n",
        "\n",
        "Next, we assemble the end-to-end model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SUtqG1Wik3L"
      },
      "source": [
        "with strategy.scope():\n",
        "  encoder = TFT5EncoderModel.from_pretrained(eng_src)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omRwwkoqJd6O"
      },
      "source": [
        "def create_model(layers_size: int, num_layers: int, dense_size: int, num_heads: int, max_length: int, encoder=None) -> tf.keras.Model:\n",
        "    # Encoder\n",
        "    encoder_inputs = tf.keras.Input(shape=(None,), dtype=\"int32\", name=\"encoder_inputs\")\n",
        "    if encoder is not None: \n",
        "        outputs = encoder(encoder_inputs)\n",
        "        encoder_outputs = outputs.last_hidden_state\n",
        "        layers_size = encoder_outputs.shape[-1]  # the size of the encoder and decoder layers must be the same\n",
        "    else:\n",
        "        encoder_outputs = EncoderTransformer(num_layers, layers_size, dense_size, num_heads, max_length, v_size_en)(encoder_inputs)\n",
        "\n",
        "    # Decoder\n",
        "    decoder_inputs = tf.keras.Input(shape=(None,), dtype=\"int32\", name=\"decoder_inputs\")\n",
        "    encoded_seq_inputs = tf.keras.Input(shape=(None, layers_size), name=\"decoder_state_inputs\")\n",
        "    decoder_outputs = DecoderTransformer(num_layers, layers_size, dense_size, num_heads, max_length, v_size_it)(decoder_inputs, encoded_seq_inputs)\n",
        "    # decoder_outputs = layers.Dropout(0.4)(decoder_outputs)\n",
        "    decoder_outputs = layers.Dense(v_size_it, activation=\"softmax\")(decoder_outputs)\n",
        "    decoder = tf.keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs, name=\"decoder_transformer\")\n",
        "\n",
        "    # Final model\n",
        "    decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "    transformer = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\")\n",
        "    return transformer"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBji4C_qmXg-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bc1884a-c688-467d-fc1d-1be79890c9d0"
      },
      "source": [
        "with strategy.scope():\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
        "    transformer = create_model(512, 6, 2048, 8)\n",
        "    transformer.summary()\n",
        "    transformer.compile(opt, loss = \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " encoder_transformer (EncoderTr  (None, None, 512)   79465472    ['encoder_inputs[0][0]']         \n",
            " ansformer)                                                                                       \n",
            "                                                                                                  \n",
            " decoder_transformer (Functiona  (None, None, 31102)  145324414  ['decoder_inputs[0][0]',         \n",
            " l)                                                               'encoder_transformer[0][0]']    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 224,789,886\n",
            "Trainable params: 224,789,886\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mad4pECqsWWS"
      },
      "source": [
        "## **Training the model**\n",
        "\n",
        "We'll use accuracy as a quick way to monitor training progress on the validation data.\n",
        "Note that machine translation typically uses BLEU scores as well as other metrics, rather than accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGqZaPCi3mqU"
      },
      "source": [
        "with strategy.scope():\n",
        "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath='./translator_base.h5', save_weights_only = True, monitor='val_loss', mode='auto', save_best_only=True)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "id": "VR8fzpHEsWWS",
        "outputId": "d30e12ef-ab39-4346-d9fd-313ee860bfab"
      },
      "source": [
        "epochs = 20  # This should be at least 30 for convergence\n",
        "transformer.fit(tr_batches, epochs=epochs, validation_data = val_batches, callbacks=[model_checkpoint_callback])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond/Identity:0' shape=(None, 22) dtype=int32>, <tf.Tensor 'cond/Identity_8:0' shape=(None, 22) dtype=int32>, <tf.Tensor 'cond/Identity_16:0' shape=(None, 22) dtype=int32>]\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond/Identity:0' shape=(None, 22) dtype=int32>, <tf.Tensor 'cond/Identity_8:0' shape=(None, 22) dtype=int32>, <tf.Tensor 'cond/Identity_16:0' shape=(None, 22) dtype=int32>]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2201/2201 [==============================] - ETA: 0s - loss: 1.0684 - accuracy: 0.6042"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond/Identity:0' shape=(None, 22) dtype=int32>, <tf.Tensor 'cond/Identity_8:0' shape=(None, 22) dtype=int32>, <tf.Tensor 'cond/Identity_16:0' shape=(None, 22) dtype=int32>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2201/2201 [==============================] - 555s 211ms/step - loss: 1.0684 - accuracy: 0.6042 - val_loss: 0.5603 - val_accuracy: 0.7420\n",
            "Epoch 2/20\n",
            "2201/2201 [==============================] - 396s 180ms/step - loss: 0.4536 - accuracy: 0.7728 - val_loss: 0.3141 - val_accuracy: 0.8213\n",
            "Epoch 3/20\n",
            "2201/2201 [==============================] - 395s 179ms/step - loss: 0.2967 - accuracy: 0.8237 - val_loss: 0.2285 - val_accuracy: 0.8505\n",
            "Epoch 4/20\n",
            "2201/2201 [==============================] - 395s 179ms/step - loss: 0.2260 - accuracy: 0.8480 - val_loss: 0.1845 - val_accuracy: 0.8670\n",
            "Epoch 5/20\n",
            "2201/2201 [==============================] - 397s 180ms/step - loss: 0.1866 - accuracy: 0.8625 - val_loss: 0.1579 - val_accuracy: 0.8775\n",
            "Epoch 6/20\n",
            "2201/2201 [==============================] - 395s 180ms/step - loss: 0.1613 - accuracy: 0.8724 - val_loss: 0.1435 - val_accuracy: 0.8840\n",
            "Epoch 7/20\n",
            "2201/2201 [==============================] - 396s 180ms/step - loss: 0.1442 - accuracy: 0.8793 - val_loss: 0.1339 - val_accuracy: 0.8881\n",
            "Epoch 8/20\n",
            "2201/2201 [==============================] - 396s 180ms/step - loss: 0.1322 - accuracy: 0.8846 - val_loss: 0.1280 - val_accuracy: 0.8912\n",
            "Epoch 9/20\n",
            "2201/2201 [==============================] - 397s 180ms/step - loss: 0.1226 - accuracy: 0.8891 - val_loss: 0.1240 - val_accuracy: 0.8929\n",
            "Epoch 10/20\n",
            "2201/2201 [==============================] - 396s 180ms/step - loss: 0.1155 - accuracy: 0.8928 - val_loss: 0.1209 - val_accuracy: 0.8952\n",
            "Epoch 11/20\n",
            " 462/2201 [=====>........................] - ETA: 4:49 - loss: 0.1120 - accuracy: 0.8943"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-b1e5d6a3af7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m  \u001b[0;31m# This should be at least 30 for convergence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1219\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \"\"\"\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    548\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \"\"\"\n\u001b[1;32m   1148\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1113\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "fOvr3NkVg1Pi",
        "outputId": "2585539a-f15d-4e4c-9987-3cd61b7b8ecf"
      },
      "source": [
        "ts_loss, ts_accuracy = transformer.evaluate(make_batches(ts_set, batch_size))\n",
        "print(\"Test loss: {0}\\nTest accuracy: {1}\".format(ts_loss, ts_accuracy))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-3c13b494dead>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mts_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test loss: {0}\\nTest accuracy: {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2860\u001b[0m     \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2861\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2862\u001b[0;31m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[1;32m   2863\u001b[0m                          \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2864\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
            "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "fEdpAMpbVLou",
        "outputId": "e8a2609b-df6b-44b7-a292-adfc3572481f"
      },
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    transformer, to_file='model_base.png', show_shapes=True, dpi=90\n",
        ")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bw_Et-rpJKuC"
      },
      "source": [
        "transformer.save_weights('./translator_base.h5', overwrite=True)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj4TsHwysWWS"
      },
      "source": [
        "## **Translator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZtPZMFHU3Sn"
      },
      "source": [
        "tokenizer_it = BertTokenizer.from_pretrained(ita_src)\n",
        "with strategy.scope():\n",
        "  transformer = create_model(512, 6, 2048, 8)\n",
        "  transformer.load_weights('./translator_base.h5')"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiB9dW8VsWWS"
      },
      "source": [
        "class Translator:\n",
        "\n",
        "    def __init__(tokenizer_src, tokenizer_dst, max_length: int, transformer: tf.keras.Model) -> None:\n",
        "        self.tokenizer_src = tokenizer_src\n",
        "        self.tokenizer_dst = tokenizer_dst\n",
        "        self.max_length = max_length\n",
        "        self.transformer = transformer\n",
        "\n",
        "    def translate(input_sentence: str) -> (list, str):\n",
        "        tokenized_input_sentence = self.tokenizer_src(input_sentence, return_tensors='tf', add_special_tokens=True,\n",
        "                                                max_length = self.max_length, padding='max_length', truncation=True).data[\"input_ids\"]\n",
        "        decoded_sentence = \"[CLS]\"\n",
        "        list_tokens=[decoded_sentence]\n",
        "        for i in range(self.max_length):\n",
        "            decoded_sentence = self.tokenizer_dst.convert_tokens_to_string(list_tokens)\n",
        "            tokenized_target_sentence = self.tokenizer_dst(decoded_sentence, return_tensors='tf', add_special_tokens=False,\n",
        "                                                    max_length = self.max_length, padding='max_length').data['input_ids']\n",
        "            predictions = self.transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "            sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "            sampled_token = self.tokenizer_dst.ids_to_tokens[sampled_token_index]\n",
        "          \n",
        "            if sampled_token == \"[SEP]\":\n",
        "              decoded_sentence = self.tokenizer_dst.convert_tokens_to_string(list_tokens[1:])\n",
        "              break\n",
        "            \n",
        "            list_tokens.append(sampled_token)\n",
        "        \n",
        "        return list_tokens, decoded_sentence"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhBNEDomEfu-",
        "outputId": "5119ea10-d3a8-4449-e0a3-a6c2de395f80"
      },
      "source": [
        "en = \"My house has several bedrooms.\"\n",
        "tokens, translated = decode_sequence(en)\n",
        "print([en, translated])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['My house has several bedrooms.', 'La mia casa ha diverse camere da letto .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxerVzMD_EOD"
      },
      "source": [
        "from transformers import BertTokenizer, BertTokenizerFast, TFBertModel, TFT5EncoderModel, T5TokenizerFast, DistilBertTokenizerFast, TFDistilBertModel\n",
        "\n",
        "encoder_models = {\n",
        "    \"bert\" : {\n",
        "        \"tokenizer\" : BertTokenizerFast.from_pretrained(\"bert-base-cased\"),\n",
        "        \"encoder\" : TFBertModel.from_pretrained(\"bert-base-cased\"),\n",
        "    },\n",
        "    \"t5\" : {\n",
        "        \"tokenizer\" : T5TokenizerFast.from_pretrained(\"t5-base\"),\n",
        "        \"encoder\" : TFT5EncoderModel.from_pretrained(\"t5-base\"),\n",
        "    },\n",
        "    \"distil_bert\" : {\n",
        "        \"tokenizer\" : DistilBertTokenizerFast.from_pretrained(\"distilbert-base-cased\"),\n",
        "        \"encoder\" : TFDistilBertModel.from_pretrained(\"distilbert-base-cased\"),\n",
        "    },\n",
        "}"
      ],
      "execution_count": 34,
      "outputs": []
    }
  ]
}